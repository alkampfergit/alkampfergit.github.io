<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Devops on Codewrecks</title><link>https://www.codewrecks.com/tags/devops/</link><description>Recent content in Devops on Codewrecks</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 10 Aug 2021 20:00:00 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/tags/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Fine control of compression level in 7zip</title><link>https://www.codewrecks.com/post/general/some-thoughts-over-7zip/</link><pubDate>Tue, 10 Aug 2021 20:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/general/some-thoughts-over-7zip/</guid><description>&lt;p>Even if 7zip is not a real DevOps argument, it is really interesting in the context of a build pipeline and &lt;strong>artifacts publishing&lt;/strong>. AzureDevops Pipeilne and GitHub actions have &lt;strong>dedicated actions to upload artifacts to the result of the pipeline/action&lt;/strong> but I often do not like this approach. Even if you can download everything as a zip, I like to create different archives before uploading, for at least two reasons&lt;/p></description></item><item><title>Docker-compose to speed up setup dev environment</title><link>https://www.codewrecks.com/post/general/docker-compose-quick-start/</link><pubDate>Sat, 22 Aug 2020 08:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/general/docker-compose-quick-start/</guid><description>&lt;p>Even if you do not plan to use Docker to distribute your application you can use it to speedup setup of development environment, for new developers and for new machines. I have a project where we use MongoDb and ElasticSearch, &lt;strong>mongodb should be authenticated and ElasticSearch needs to have some special plugin installed&lt;/strong>.&lt;/p>
&lt;blockquote>
&lt;p>Time to setup a new machine sometimes is high due to dependencies.&lt;/p>&lt;/blockquote>
&lt;p>I&amp;rsquo;m aware that for experienced user setting up mongodb and ElasticSearch is not a complex task, but nevertheless you usually can have some problem.&lt;/p></description></item><item><title>Windows Docker Container for Azure Devops Build agent</title><link>https://www.codewrecks.com/post/old/2020/01/windows-docker-container-for-azure-devops-build-agent/</link><pubDate>Sat, 25 Jan 2020 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/01/windows-docker-container-for-azure-devops-build-agent/</guid><description>&lt;p>Thanks to Docker Compose, &lt;a href="http://www.codewrecks.com/blog/index.php/2019/12/27/azure-devops-agent-with-docker-compose/">I can spin off an agent for Azure Devops in mere seconds&lt;/a> (once you have all the images). Everything I need is just insert the address of my account a valid token and an agent is ready.&lt;/p>
&lt;p>&lt;strong>With.NET core everything is simple, because we have a nice build task that automatically install.NET Core SDK in the agent,&lt;/strong> the very same for node.js. This approach is really nice, because it does not require to preinstall too much stuff in your agent, everything is downloaded and installed on the fly when a build needs that specific tooling.&lt;/p></description></item><item><title>Azure DevOps multi stage pipeline environments</title><link>https://www.codewrecks.com/post/old/2019/11/azure-devops-multi-stage-pipeline-environments/</link><pubDate>Tue, 12 Nov 2019 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/11/azure-devops-multi-stage-pipeline-environments/</guid><description>&lt;p>In a previous post on &lt;a href="http://www.codewrecks.com/blog/index.php/2019/10/21/release-app-with-azure-devops-multi-stage-pipeline/">releasing with Multi Stage Pipeline and YAML code&lt;/a> I briefly introduced the concept of environments. In that example I used an environment called single_env and &lt;strong>you can be surprised that, by default, an environment is automatically created when the release runs.&lt;/strong> This happens because an environment can be seen as sets of resources used as target for deployments, but in the actual preview version, in Azure DevOps, you can only add Kubernetes resources. The question is: &lt;strong>why have I used an environment to deploy an application to Azure if there is no connection between the environment and your azure resources?&lt;/strong> &amp;gt; At this stage of the preview, we can only connect Kubernetes to an environment, no other physical resource can be linked.&lt;/p></description></item><item><title>How to manage PowerShell installation scripts</title><link>https://www.codewrecks.com/post/old/2016/06/how-to-manage-powershell-installation-scripts/</link><pubDate>Sat, 18 Jun 2016 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/06/how-to-manage-powershell-installation-scripts/</guid><description>&lt;p>In  &lt;a href="http://www.codewrecks.com/blog/index.php/2016/06/03/create-a-release-manager-in-tfs-with-powershell-and-zipped-artifacts/">previous post&lt;/a> I explained how I like to release software using a simple paradigm:&lt;/p>
&lt;blockquote>
&lt;p>build produces one zipped file with everything needed for a release, then a PowerShell scripts accepts the path of this zipped release and installation parameters and executes every step to install/upgrade the software.&lt;/p>&lt;/blockquote>
&lt;p>This approach has numerous advantages, first of all &lt;strong>you can always test script with PowerShell ISE in a Developer Machine&lt;/strong>. Just download from build artifacts the version you want to use for test, load installation script in PowerShell ISE, then run the script, and if something went wrong (the script has a bug or needs to be updated) just debug and modify it until it works.&lt;/p></description></item><item><title>Running Unit Tests on different machine during TFS 2015 build</title><link>https://www.codewrecks.com/post/old/2016/06/running-unit-tests-on-different-machine-during-tfs-2015-build/</link><pubDate>Sat, 04 Jun 2016 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/06/running-unit-tests-on-different-machine-during-tfs-2015-build/</guid><description>&lt;p>First of all I need to thanks my friend &lt;a href="http://blog.ehn.nu/">Jackob Ehn&lt;/a> that pointed me to the right direction to create a particular build.  In this post &lt;strong>I’ll share with you my journey to run tests on a different machine than the one that is running the build&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>For some build it is interesting to have the ability to run some Unit Test (nunit in my scenario) on a machine different from that one that is running the build.&lt;/strong> There are a lot of legitimate reasons for doing this, for a project I’m working with, to run a set of test I need to have a huge amount of pre-requisites installed (LibreOffice, ghostscript, etc). Instead of installing those prerequisite on all agent machines, or install those one on a single build agent and using capabilities, I’d like to being able &lt;strong>to run the build on any build agent, but run the test in a specific machine that had all the prerequisite installed.&lt;/strong> &amp;gt; Sometimes it is necessary to run tests during build on machine different from that one where the build agent is running.&lt;/p></description></item><item><title>Create a Release with PowerShell Zipped Artifacts and Chocolatey</title><link>https://www.codewrecks.com/post/old/2016/06/create-a-release-manager-in-tfs-with-powershell-and-zipped-artifacts/</link><pubDate>Fri, 03 Jun 2016 14:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/06/create-a-release-manager-in-tfs-with-powershell-and-zipped-artifacts/</guid><description>&lt;p>In previous post I described how to create a simple PowerShell scripts that is capable of installing a software starting from a zipped file that contains the “release” of a software (produced by a build) and some installation parameters. Once you have this scenario up and running, releasing your software automatically is quite simple.&lt;/p>
&lt;blockquote>
&lt;p>Once you automated the installation with a PowerShell script plus an archive file with Everything is needed to install the software, you are only a step away from Continuous Deployment.&lt;/p></description></item><item><title>Using PowerShell scripts to deploy your software</title><link>https://www.codewrecks.com/post/old/2016/06/using-powershell-scripts-to-deploy-your-software/</link><pubDate>Fri, 03 Jun 2016 12:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/06/using-powershell-scripts-to-deploy-your-software/</guid><description>&lt;p>I often use PowerShell scripts to package a “release” of a software during a build because it gives me a lots of flexibility.&lt;/p>
&lt;p>&lt;a href="http://www.codewrecks.com/blog/index.php/2015/06/30/manage-artifacts-with-tfs-build-vnext/">Manage artifacts with TFS Build vNext&lt;/a>&lt;/p>
&lt;p>&lt;a href="http://www.codewrecks.com/blog/index.php/2016/01/30/different-approaches-for-publishing-artifacts-in-build-vnext/">Different approaches for publishing Artifacts in build vNext&lt;/a>&lt;/p>
&lt;p>&lt;strong>The advantage of using PowerShell is complete control over what will be included in the “release” package&lt;/strong>. This allows you to manipulate configuration files, remove unnecessary files, copy files from somewhere else in the repository, etc etc.&lt;/p></description></item><item><title>Avoid using Shell command in PowerShell scipts</title><link>https://www.codewrecks.com/post/old/2016/05/avoid-using-shell-command-in-powershell-scipts/</link><pubDate>Fri, 27 May 2016 15:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/05/avoid-using-shell-command-in-powershell-scipts/</guid><description>&lt;p>I have setup scripts that are used to install software, they are simply based on this paradigm&lt;/p>
&lt;blockquote>
&lt;p>The build produces a zip file that contains everything needed to install the software, then we have a script that accepts the zip file as parameter as well as some other parameters and does install sofwtare on a local machine&lt;/p>&lt;/blockquote>
&lt;p>This simple paradigm is perfect, because &lt;strong>we can manually install a software launching powershell, or we can create a Chocolatey package to automate the installation.&lt;/strong> Clearly you can use the very same script to release the software inside TFS Release Management.&lt;/p></description></item><item><title>Deploying a click-once application with build vNext in Azure Blob Storage</title><link>https://www.codewrecks.com/post/old/2015/12/rename-xmlrpc-php-on-your-wordpress-installation-2/</link><pubDate>Wed, 30 Dec 2015 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/12/rename-xmlrpc-php-on-your-wordpress-installation-2/</guid><description>&lt;p>Thanks to the new build system in TFS / VSTS, publishing an application with Click-once during a build is really simple.&lt;/p>
&lt;h2 id="versioning-the-click-once-app">Versioning the click-once app&lt;/h2>
&lt;h2>&lt;/h2>
&lt;p>The project is using Git and GitFlow, thus it comes natural &lt;strong>to use GitVersion (as described in a&lt;/strong> &lt;a href="http://www.codewrecks.com/blog/index.php/2015/10/17/integrating-gitversion-and-gitflow-in-your-vnext-build/">&lt;strong>previous post&lt;/strong>&lt;/a> &lt;strong>) to automatically add Semantic Versioning&lt;/strong>. In previous post I’ve demonstrated how to use this technique to publish Nuget Packages and nothing changes for Click Once applications.&lt;/p></description></item><item><title>Build vNext support for deploying bits to Windows machines</title><link>https://www.codewrecks.com/post/old/2015/06/build-vnext-support-for-deploying-bits-to-windows-machines/</link><pubDate>Sat, 20 Jun 2015 13:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/06/build-vnext-support-for-deploying-bits-to-windows-machines/</guid><description>&lt;p>One of the most interesting trend of DevOps movement is continuous deployment using build machines. Once you get your continuous build up and running, the next step is &lt;strong>customizing the build to deploy on one or more test environments&lt;/strong>. If you do not need to deploy in production, there is no need of a controlled release pipeline (Ex: Release Management) and using a simple build is the most productive choiche. In this scenario &lt;strong>one of the biggest pain is moving bits from the build machine to target machines.&lt;/strong> Once build output is moved to a machine, installing bits is usually only a matter of using some PowerShell script.&lt;/p></description></item><item><title>Build vNext distributing load to different agents</title><link>https://www.codewrecks.com/post/old/2015/06/build-vnext-distributing-load-to-different-agents/</link><pubDate>Sat, 06 Jun 2015 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/06/build-vnext-distributing-load-to-different-agents/</guid><description>&lt;p>One of the major benefit of the new build infrastructure of TFS and Visual Studio Online is the &lt;strong>easy deployment of build agents&lt;/strong>. The downside of this approach is that your infrastructure become full of agents, and you should have some way to &lt;strong>determine which agent(s) to use for a specific build.&lt;/strong> The problem is:&lt;/p>
&lt;blockquote>
&lt;p>avoid running builds in machines that are “not appropriate” for that build.&lt;/p>&lt;/blockquote>
&lt;h2 id="running-on-a-specific-agent">Running on a specific agent&lt;/h2>
&lt;p>If you are customizing a build, or if you are interested in running the build on a specific agent in a specific machine (ex: local agent), the solution is super easy, Just edit build definition and in General tab add a * &lt;strong>demand&lt;/strong> *named Agent.Name with the value of the name of the specified Agent.&lt;/p></description></item><item><title>Fix of ChangeConnectionString resource in DSC Script to deploy Web Site</title><link>https://www.codewrecks.com/post/old/2014/06/fix-of-changeconnectionstring-resource-in-dsc-script-to-deploy-web-site/</link><pubDate>Tue, 17 Jun 2014 04:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/fix-of-changeconnectionstring-resource-in-dsc-script-to-deploy-web-site/</guid><description>&lt;!--StartFragment-->- [How 
&lt;p>&lt;br>to deploy a web site with Powershell DSC](&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/11/how-to-deploy-web-site-with-powershell-dsc/">http://www.codewrecks.com/blog/index.php/2014/06/11/how-to-deploy-web-site-with-powershell-dsc/&lt;/a>)&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/12/how-to-deploy-a-web-site-with-powershell-part-2/">How&lt;br>
&lt;br>to Deploy a Web Site with PowerShell DSC Part 2&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/15/deploying-web-site-with-powershell-dsc-part-3/">How to Deploy a Web Site with PowerShell DSC Part 3&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In the second part of this series I’ve received a really good comment by Rob Cannon, that warn me about an error in my ChangeConnectionString resource. In that article I told you that is ok for the Test part to return always False, so the Set Script is always run, because it is idempotent. This is true if you are using the Push Model, &lt;strong>but if you are using the Pull Model instead, every 30 minutes the DSC will be applied and web config will be changed, so your application pool will be restarted&lt;/strong>. This is not a good situation, so I decided to change the script fixing the Test Part.&lt;/p></description></item><item><title>Deploying Web Site With PowerShell DSC part 3</title><link>https://www.codewrecks.com/post/old/2014/06/deploying-web-site-with-powershell-dsc-part-3/</link><pubDate>Sun, 15 Jun 2014 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/deploying-web-site-with-powershell-dsc-part-3/</guid><description>&lt;ul>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/11/how-to-deploy-web-site-with-powershell-dsc/">How to deploy a web site with Powershell DSC&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/12/how-to-deploy-a-web-site-with-powershell-part-2/">How to Deploy a Web Site with PowerShell DSC Part 2&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this last part of this series I’ll explain how to deploy database projects output to local database of node machine. It was the most difficult due to some errors present in the xDatabase resource. Actually &lt;strong>I have a couple of Database Projects in my solution, the first one define the structure of the database needed by my application while the second one reference the first and installs only some test data&lt;/strong> with a Post Deploy Script. You can read about this technique in my previous post &lt;a href="http://www.codewrecks.com/blog/index.php/2013/08/05/manage-test-data-in-visual-studio-database-project/">Manage Test Data in Visual Studio Database Project&lt;/a> Sadly enough, the xDatabase resource of DSC is still very rough and grumpy.&lt;/p></description></item><item><title>How to deploy a Web Site with Powershell Part 2</title><link>https://www.codewrecks.com/post/old/2014/06/how-to-deploy-a-web-site-with-powershell-part-2/</link><pubDate>Thu, 12 Jun 2014 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/how-to-deploy-a-web-site-with-powershell-part-2/</guid><description>&lt;p>In the first part on “&lt;a href="http://www.codewrecks.com/blog/index.php/2014/06/11/how-to-deploy-web-site-with-powershell-dsc/">how to deploy a web site with Powershell DSC&lt;/a>” I’ve explained the basic of a PowerShell DSC based script to install IIS and the required version of.NET Framework on target environment; &lt;strong>now it is time to deploy a Web Site&lt;/strong>. In my scenario I want to use a port different from 80, because in test servers is a common practice installing multiple version of sites in different ports to distinguish between various deploy (Dev, Test, QA, etc). Here are the sequence of resources I use to deploy my site.&lt;/p></description></item><item><title>How to Deploy Web Site with PowerShell DSC</title><link>https://www.codewrecks.com/post/old/2014/06/how-to-deploy-web-site-with-powershell-dsc/</link><pubDate>Wed, 11 Jun 2014 05:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/how-to-deploy-web-site-with-powershell-dsc/</guid><description>&lt;p>I do not want to create another tutorial on DSC and I suggest you reading some introductory articles like: &lt;a href="http://blogs.technet.com/b/privatecloud/archive/2013/08/30/introducing-powershell-desired-state-configuration-dsc.aspx">Introducing PowerShell Desired State Configuration&lt;/a> before reading this article. Since I’m pretty new with PowerShell and I’m starting experimenting with DSC I decided to &lt;strong>start creating a script to deploy my favorite test application (TailspinToys :) ) on a single Windows 2012 R2 server using only DSC&lt;/strong>. This post aims to share my thought on the subject.&lt;/p></description></item></channel></rss>