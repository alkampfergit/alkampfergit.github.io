<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tika on Codewrecks</title><link>https://www.codewrecks.com/tags/tika/</link><description>Recent content in Tika on Codewrecks</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 24 Jun 2014 06:00:37 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/tags/tika/index.xml" rel="self" type="application/rss+xml"/><item><title>Index documents content with Solr and Tika</title><link>https://www.codewrecks.com/post/old/2014/06/index-documents-content-with-solr-and-tika/</link><pubDate>Tue, 24 Jun 2014 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/index-documents-content-with-solr-and-tika/</guid><description>&lt;p>I’ve blogged in the past about &lt;a href="http://www.codewrecks.com/blog/index.php/2013/05/25/import-folder-of-documents-with-apache-solr-4-0-and-tika/">indexing entire folders of documents with solr and Tika&lt;/a> with Data Import Handler. This approach has pro and cons. On the &lt;strong>good side, once you’ve understand the basics, setting everything up and running is a matter of a couple of hours max, on the wrong side, using a DIH gives you little controls over the entire process&lt;/strong>.&lt;/p>
&lt;p>As an example, I’ve had problem with folder with jpg images, because the extractor crashes due to a missing library. If you do not configure correctly the import handler, every error stops the entire import process. Another problem is that document content is not subdivided into pages even if Tika can give you this kind of information. Finally, &lt;strong>you need to have all of your documents inside a folder to be indexed&lt;/strong>. &lt;strong>In real situation it is quite often preferable to have more control over the index process. Lets examine how you can use tika from your C# code&lt;/strong>.&lt;/p></description></item><item><title>Index a folder of multilanguage documents in Solr with Tika</title><link>https://www.codewrecks.com/post/old/2014/06/index-a-folder-of-multilanguage-documents-in-solr-with-tika/</link><pubDate>Sat, 14 Jun 2014 13:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2014/06/index-a-folder-of-multilanguage-documents-in-solr-with-tika/</guid><description>&lt;p>Previous Posts on the serie&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2013/05/25/import-folder-of-documents-with-apache-solr-4-0-and-tika/">Import folder of Documents with Apache Solr 4.0 and Tika&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.codewrecks.com/blog/index.php/2013/05/27/hilight-matched-text-inside-documents-indexed-with-solr-plus-tika/">Highlight matched test inside documents indexed with Solr And Tika&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Everything is up and running, but now &lt;strong>requirements change, documents can have multiple languages (italian and english in my scenario) and we want to do the simplest thing that could possibly work&lt;/strong>. First of all I change the schema of the core in solr to support language specific fields with wildcards.&lt;/p></description></item><item><title>Hilight matched text inside documents indexed with Solr plus Tika</title><link>https://www.codewrecks.com/post/old/2013/05/hilight-matched-text-inside-documents-indexed-with-solr-plus-tika/</link><pubDate>Mon, 27 May 2013 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2013/05/hilight-matched-text-inside-documents-indexed-with-solr-plus-tika/</guid><description>&lt;p>I’ve already dealt on how to &lt;a href="http://www.codewrecks.com/blog/index.php/2013/05/25/import-folder-of-documents-with-apache-solr-4-0-and-tika/">index documents with Solr and Tika&lt;/a> and in this article I’ll explain how you can not only search for documents that match your query, but &lt;strong>returns even some text extract that shows where the document match the query&lt;/strong>. To achieve this, you should store the full content of the document inside your index, usually I create a couple of fields, one called Content that will contain the content of the file, and with a copyfield directive (  &amp;lt;copyField source=”content” dest=”text”/&amp;gt; ) automatically copy that value inside the catch all field called text.&lt;/p></description></item><item><title>Import folder of documents with Apache Solr 40 and tika</title><link>https://www.codewrecks.com/post/old/2013/05/import-folder-of-documents-with-apache-solr-4-0-and-tika/</link><pubDate>Sat, 25 May 2013 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2013/05/import-folder-of-documents-with-apache-solr-4-0-and-tika/</guid><description>&lt;p>In a previous article I showed how simple is to &lt;a href="http://www.codewrecks.com/blog/index.php/2013/04/29/loading-data-from-sql-server-to-solr-with-a-data-import-handler/">import data from a Sql database into Solr with a Data Import Handler&lt;/a>, in this article I’ll use a similar technique to &lt;strong>import documents stored inside a folder&lt;/strong>.&lt;/p>
&lt;p>This feature is exposed by the &lt;strong>integration with Tika, an open source document analyzer capable of extracting text by various formats of files&lt;/strong>. Thanks to this library solr is capable of crawling an entire directory, indexing every document inside it with really minimal configuration. Apache Tika is a standalone project, you can find all &lt;a href="https://tika.apache.org/1.3/formats.html">supported formats here&lt;/a> and you can use directly from your java (or.NET code) but thanks to Solr Integration setting everything up is a real breeze.&lt;/p></description></item></channel></rss>