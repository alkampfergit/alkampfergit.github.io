<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sql Server on Codewrecks</title><link>https://www.codewrecks.com/tags/sql-server/</link><description>Recent content in Sql Server on Codewrecks</description><generator>Hugo</generator><language>en</language><lastBuildDate>Thu, 19 Feb 2015 18:00:37 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/tags/sql-server/index.xml" rel="self" type="application/rss+xml"/><item><title>Error TF53001 The database operation was canceled by an administrator</title><link>https://www.codewrecks.com/post/old/2015/02/error-tf53001-the-database-operation-was-canceled-by-an-administrator/</link><pubDate>Thu, 19 Feb 2015 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/02/error-tf53001-the-database-operation-was-canceled-by-an-administrator/</guid><description>&lt;h4 id="a-customer-updated-his-tfs-2010-to-2013-in-a-new-machine-running-windows-server-2012-r2-and-sql-server-2014-everything-went-fine-until-after-few-days-they-started-having-an-error-whenever-he-tried-to-do-a-getlatest-or-a-check-in-or-check-out-operation">A customer updated his TFS 2010 to 2013 in a new machine running Windows Server 2012 R2 and Sql Server 2014. Everything went fine, until after few days they started having an error whenever he tried to do a GetLatest or a Check-in or Check-out operation.&lt;/h4>
&lt;blockquote>
&lt;p>&lt;strong>Error TF53001: The database operation was canceled by an administrator&lt;/strong> Actually this error is not really informative, so I asked them to verify Event Viewer on the server (&lt;em>an operation you should always do whenever you have wrong behavior of your TFS&lt;/em>). For each client operation that gave error they have this Event Error logged&lt;/p></description></item><item><title>Force Sql server index usage in query</title><link>https://www.codewrecks.com/post/old/2012/03/force-sql-server-index-usage-in-query/</link><pubDate>Thu, 08 Mar 2012 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/03/force-sql-server-index-usage-in-query/</guid><description>&lt;p>Sometimes sql server surprises me, I have a really stupid table with seven columns and one of these columns contains great amount of text data. I need to select the minimum Id based on a date filter, and so I issued a really simple query like:&lt;/p>
&lt;p>&lt;em>Select min(TN.Id) &lt;br>
from TableName TN &lt;br>
where TN.timestamp &amp;gt;= ‘20110201’&lt;/em>&lt;/p>
&lt;p>This is a really simple query, but since the table is about 15 GB due to the large amount of text stored in it, it got executed in 140 secs, so I decided to create a simple index based on timestamp and id columns, but with my great surprise, even with the index, previous query still resort to a full table scan and needs 140 secs to be executed. The index is newly created, &lt;a href="http://msdn.microsoft.com/en-us/library/ms188917.aspx">it is not fragmented&lt;/a>, statistics are updated, so I really do not understand where is the problem.&lt;/p></description></item><item><title>Check progress of DBCC CHECKDB</title><link>https://www.codewrecks.com/post/old/2012/02/check-progress-of-dbcc-checkdb/</link><pubDate>Tue, 07 Feb 2012 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/02/check-progress-of-dbcc-checkdb/</guid><description>&lt;p>If you issue a &lt;a href="http://msdn.microsoft.com/en-us/library/ms176064.aspx">DBCC CHECKDB&lt;/a> on a big database to verify for consistency errors, it will take a long time to complete, but the Management Studio windows usually does not give you any hint about how long does it take, or a percentage progress. Luckily enough sql server has a Dynamic Management View that can solve your problem.&lt;/p>
&lt;p>This is the SQL code to visualize progress of the operation&lt;/p>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>SELECT session_id ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>request_id ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>percent_complete ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimated_completion_time ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>DATEADD(ms,estimated_completion_time,GETDATE()) AS EstimatedEndTime,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>start_time ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status ,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>command
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>FROM sys.dm_exec_requests
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>WHERE database_id = &lt;span style="color:#ae81ff">16&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;p>In my example I filtered the results only for the database and used the Id of the database that you can obtain with the &lt;a href="http://msdn.microsoft.com/en-us/library/ms186274.aspx">DB_ID&lt;/a> function.&lt;/p></description></item><item><title>When it is time to tweak SQL Server queries</title><link>https://www.codewrecks.com/post/old/2012/01/when-it-is-time-to-tweak-sql-server-queries/</link><pubDate>Tue, 31 Jan 2012 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/01/when-it-is-time-to-tweak-sql-server-queries/</guid><description>&lt;p>I’ve a stored procedure with a query that runs on a quite big database, it was slow (more than one minute to run) and was optimized using a temp table. The result is that execution time dropped to ~2 secs, and since this was acceptable the optimization stopped.&lt;/p>
&lt;p>After a couple of months, the query become really slow again, it got executed in ~30 secs and I started to investigate why.&lt;/p></description></item><item><title>Hardcore fix error in Sql Server database</title><link>https://www.codewrecks.com/post/old/2012/01/hardcore-fix-error-in-sql-server-database/</link><pubDate>Tue, 31 Jan 2012 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/01/hardcore-fix-error-in-sql-server-database/</guid><description>&lt;p>In a production Sql Server database we had some issue with the hardware, the result is that one very big database started to gave us errors on DBCC CHECKDB, the error is the following one.&lt;/p>
&lt;blockquote>
&lt;p>Msg 8929, Level 16, State 1, Line 1 &lt;br>
Object ID xxxxxx, index ID 1, partition ID xxxxxx, alloc unit ID xxxxx (type In-row data): Errors found in off-row data with ID xxxxxxx owned by data record identified by RID = (3:34252:4)&lt;/p></description></item><item><title>Why Management Studio forces you to know SQL</title><link>https://www.codewrecks.com/post/old/2011/12/why-management-studio-forces-you-to-know-sql/</link><pubDate>Wed, 28 Dec 2011 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/12/why-management-studio-forces-you-to-know-sql/</guid><description>&lt;p>Suppose you have a big table with about 3 GB of data in and you need to add a nullable new column on it, you can open SSMS, open the table in designer and create a new column of type Int called sclo_durationInMinutes, press save and the table gets update quite immediately.&lt;/p>
&lt;p>Then you realize that the user want the duration in Minutes as a floating point number, so you open the designer, change the type of the sclo_durationInMinutes from Int to Float and press save…. after 30 seconds SSMS tells you that you got a timeout. If you look at the change script you can verify, with HORROR, that changing the type of a column is done with the creation of a temporary table, copy all the data (3 GB) in the temp table and finally deleting the old table and renaming the temp table with the name of the original table… REALLY?&lt;/p></description></item><item><title>Custom XML Serialization</title><link>https://www.codewrecks.com/post/old/2011/12/custom-xml-serialization/</link><pubDate>Thu, 01 Dec 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/12/custom-xml-serialization/</guid><description>&lt;p>Another advantage of sto&lt;a href="http://www.codewrecks.com/blog/index.php/2011/06/13/leverage-the-concept-of-state-of-your-entities/">ring properties of entities into a state object&lt;/a> based on a Dictionary, is the ability to easily serialize objects in custom formats. As an example I create an XML serializer that is capable to serialize an entity in a custom XML format.&lt;/p>
&lt;p>I used this simple serializer to create a NHibernate User Type that permits me to save a child entity in a single XML column of SQL Server, a feature useful when you need to save objects which schema changes quite often and you do not want to keep database schema updated, or you need to store dynamic data into the DB. I now that all of you are screaming “USE NO SQL DB”, like &lt;a href="http://ravendb.net/">Raven&lt;/a>, but it is not simple to introduce new technologies into existing projects, and only to justify the need to save the 2% of objects.&lt;/p></description></item><item><title>Trim all non-alpha character from SQL string</title><link>https://www.codewrecks.com/post/old/2011/10/trim-all-non-alpha-character-from-sql-string/</link><pubDate>Fri, 28 Oct 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/10/trim-all-non-alpha-character-from-sql-string/</guid><description>&lt;p>I’have a table with some dirty data, if you select it seems that everything is ok, but since it was imported from an external source, it happens that some string field actually ends with strange non alpha char.&lt;/p>
&lt;p>The symptom is that I have some strange behavior on some data, then I verify what is the content of that row, so I issue a Select * from xxx where Name = ‘Azioni’ and got no result, so I select everything that contains Azioni and I found the record. This is the clear symptom that the field contains some strange stuff in it, so I simply to a Copy and paste in the editor to see &lt;em>exactly&lt;/em>what is stored in the field, and I found&lt;/p></description></item><item><title>Always pay attention to uniqueness to SQL Index</title><link>https://www.codewrecks.com/post/old/2011/10/always-pay-attention-to-uniqueness-to-sql-index/</link><pubDate>Thu, 06 Oct 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/10/always-pay-attention-to-uniqueness-to-sql-index/</guid><description>&lt;p>I have a database with several Gigabyte of data and query performance is usually a issue, so we need to take great care of indexes and DB optimization. Since the vast majority of data access is done with NHibernate, we have also some read-only view that we use to easy the access from the views.&lt;/p>
&lt;p>One of this view, have four left outer join from a main table to other four tables and we have a SELECT COUNT query that is quite slow, so we decide to understand how to optimize it. I started looking at the execution plan and I found this.&lt;/p></description></item><item><title>Run SSIS package from another server in workspace</title><link>https://www.codewrecks.com/post/old/2011/08/run-ssis-package-from-another-server-in-workspace/</link><pubDate>Fri, 05 Aug 2011 12:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/08/run-ssis-package-from-another-server-in-workspace/</guid><description>&lt;p>Today I needed to move some SSIS packages that actually runs on the same server where the database resides, to another server dedicated to run SSIS packages. I do not have a domain and the second server is simply in the same network as the first server. I simply reconfigured a Job to run the Package from File system (as originally configured in the original server), but now I could not use Integrated Security because I&amp;rsquo;m running the SSIS package from another PC. So I changed the connection string to include user and pwd (SQL authentication), but when I saved the job step the password simply disappeared from the connection string.&lt;/p></description></item><item><title>Sql Server Schema and scope</title><link>https://www.codewrecks.com/post/old/2011/08/sql-server-schema-and-scope/</link><pubDate>Thu, 04 Aug 2011 13:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/08/sql-server-schema-and-scope/</guid><description>&lt;p>This morning I spent 20 minutes completely puzzled on a stored procedure in Sql Server. This stored procedure is not too complex, it moves data incrementally on a denormalized table to speed up some searches. The concept is simple, I run a series of queries to obtain a list of the ids of modified entity since the last run of the stored, then I update those lines and insert the new ones.&lt;/p></description></item><item><title>Use Sql Server Query Hints with NHibernate HQL and ICriteria</title><link>https://www.codewrecks.com/post/old/2011/07/use-sql-server-query-hints-with-nhibernate-hql-and-icriteria/</link><pubDate>Sat, 23 Jul 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/07/use-sql-server-query-hints-with-nhibernate-hql-and-icriteria/</guid><description>&lt;p>When you work with Big databases with many records and &lt;em>not uniform distribution of data into columns used for join or where conditions&lt;/em>, you can have really bad performance problem due to Query Plan caching. I do not want to give a deep explanation of this problem, you can find information &lt;a href="http://legeronline.blogspot.com/2009/03/evils-of-slow-paramaterized-query-plans.html">here&lt;/a>, but I want to outline the general problem to make clear what is happening.&lt;/p>
&lt;p>We can argue a lot why this problem happens in a database engine, but basically I have a really bad situation where the db stores data of multiple customers with really non uniform distribution of data (some of them have ~1000 rows for each table, others have ~100.000 rows in some of the tables).&lt;/p></description></item><item><title>Using guid id in nhibernate index fragmentation</title><link>https://www.codewrecks.com/post/old/2011/05/using-guid-id-in-nhibernate-index-fragmentation/</link><pubDate>Mon, 16 May 2011 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/05/using-guid-id-in-nhibernate-index-fragmentation/</guid><description>&lt;p>This is a quick consideration about using id of type GUID in nhibernate. If in SQL server the cluster index is on the id (default choiche), if you use a simple guid generator you will end in high index fragmentation. This happens because if you insert a lot of objects into the table, since the physical ordering of the records (the clustered index) is on the Id field, inserting a sequence of objects with random id will insert these object randomly into the physical space of the DB. Remember that the index is a Tree that was kept ordered by its clustered index.&lt;/p></description></item><item><title>Red Gate Tools Sql Dependency Tracker</title><link>https://www.codewrecks.com/post/old/2010/04/red-gate-tools-sql-dependency-tracker/</link><pubDate>Fri, 30 Apr 2010 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2010/04/red-gate-tools-sql-dependency-tracker/</guid><description>&lt;p>I must admit that I really loves tools from &lt;a href="http://www.red-gate.com">RedGate&lt;/a> and recently I&amp;rsquo;ve discovered the &lt;a href="http://www.red-gate.com/products/SQL_Dependency_Tracker/index.htm">Sql Dependency Tracker&lt;/a>, an exceptional tool to manage dependencies between objects in a database.&lt;/p>
&lt;p>This tool is really great because with a few click you can have different graphs that represents dependency relation between objects in the database. I&amp;rsquo;m working on a legacy database, and I have two very old view that were replaced by another indexed view, that performs better and has better column names. We ported almost everything, but I need to know if some stored procedure or object still uses the old views. I simply open the Sql Dependency Tracker and immediately I found this graph&lt;/p></description></item><item><title>SSIS use parameter with ADO Net source in DataFlow</title><link>https://www.codewrecks.com/post/old/2010/04/ssis-use-parameter-with-ado-net-source-in-dataflow/</link><pubDate>Tue, 13 Apr 2010 13:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2010/04/ssis-use-parameter-with-ado-net-source-in-dataflow/</guid><description>&lt;p>I have a database where reports are done with stored procedure over the OLTP database, and we begin to suffer poor performance because we have a lot of data and sometimes reports are locked by transaction issued from components that does bulk data insertion.&lt;/p>
&lt;p>A viable solution is moving all data in a DataWarehouse server where I can copy all denormalized data. This permits me to do a report query with only a simple select over a single table, then queries are issued against a database with no lock. I decided to move data using SSIS, with incremental population and customer partition.&lt;/p></description></item><item><title>Visual Studio Database Edition First steps</title><link>https://www.codewrecks.com/post/old/2009/05/visual-studio-database-edition-first-steps/</link><pubDate>Wed, 27 May 2009 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/05/visual-studio-database-edition-first-steps/</guid><description>&lt;p>I began using Visual Studio Database Edition today, I did not used it before because I&amp;rsquo;m the only one in the team that have this edition, others developers used VS professional, but I&amp;rsquo;m the one who cares of database in this project, quite all modifications are done by myself, so I decided to create a DataBase Project.&lt;/p>
&lt;p>I was amazed because in few seconds Visual Studio scanned developement database, and creates a database project where each database object is represented by a single.sql Files. I was ready to work in 5 minutes.&lt;/p></description></item><item><title>Generate insert data for sql server tables</title><link>https://www.codewrecks.com/post/old/2009/03/generate-insert-data-for-sql-server-tables/</link><pubDate>Tue, 31 Mar 2009 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/03/generate-insert-data-for-sql-server-tables/</guid><description>&lt;p>Sometimes I need to generate insert statement, taking data from a starting database. Suppose you need to create sql installation scripts to create a database from scratch, quite often you need also to insert some initial data into some tables.&lt;/p>
&lt;p>Sql server management studio does not provide a simple way to take a table and script all its content into INSERT statement, but a simple solution can be found &lt;a href="http://www.codeproject.com/KB/database/InsertGeneratorPack.aspx">here&lt;/a>. This solution is really simple, it creates a stored into the database that can be used to generate data Es.&lt;/p></description></item><item><title>Test Drive with database</title><link>https://www.codewrecks.com/post/old/2009/01/test-drive-with-database/</link><pubDate>Tue, 20 Jan 2009 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/01/test-drive-with-database/</guid><description>&lt;p>If you need to &lt;a href="http://www.codewrecks.com/blog/index.php/2008/09/30/database-testing/">test drive with a database&lt;/a>  you can find a lot of problems. The basics of test drive with database is using a database sandbox, and creating a series of scripts that takes the database in a well known state before the run of each test.&lt;/p>
&lt;p>In my projects I use NHibernate but there are quite often also some part of the database handled with stored or accessed through a datalayer. In such a situation I cannot use the capability of nhibernate to regenerate the schema, because some tables and stored are outside the control of nhibernate.&lt;/p></description></item><item><title>SqlError quotThe server encountered a stack overflow during compile timequot</title><link>https://www.codewrecks.com/post/old/2008/08/sqlerror-the-server-encountered-a-stack-overflow-during-compile-time/</link><pubDate>Tue, 05 Aug 2008 05:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/08/sqlerror-the-server-encountered-a-stack-overflow-during-compile-time/</guid><description>&lt;p>This morning I see from a server log this frightening error.. “The server encountered a stack overflow during compile time”. Fortunately I used elmah to log all error of the site, so I immediately find the page that gives that problem.&lt;/p>
&lt;p>It turns out that in a page we used to make some query to get a list of entities that satisfies some kind of criteria, then we build a page showing all these entities.&lt;/p></description></item><item><title>detecting if finally block is executing for an manhandled exception</title><link>https://www.codewrecks.com/post/old/2008/07/detecting-if-finally-block-is-executing-for-an-manhandled-exception/</link><pubDate>Fri, 25 Jul 2008 00:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/07/detecting-if-finally-block-is-executing-for-an-manhandled-exception/</guid><description>&lt;p>&lt;a href="http://www.ayende.com/Blog/archive/8065.aspx">DisposableAction&lt;/a> pattern is one of the most useful I , I used it to manage transaction for a DataAccess helper. I begin a transaction with DataAccess.BeginTransaction() that returns an IDisposable object that automatically dispose the tranasction. Here is an example of a typical use&lt;/p>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> (DataAccess.BeginTransaction())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//Do whatever query you want with DataAccess&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DataAccess.CommitTransaction();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;!-- Code inserted with Steve Dunn's Windows Live Writer Code Formatter Plugin. http://dunnhq.com -->
&lt;p>This is similar to the TransactionScope of.NEt, but it does not involve the MSDTC. The only thing that I do not like too much is the need to call CommitTransaction() at the end of the block. It sounds unnecessary to me because committing the transaction is the &lt;em>default&lt;/em> behavior of the block. The purpose of the transaction is to be sure that a series of operation are done atomically, so in my opinion the default behavior is committing the transaction and only if something is wrong we call Rollback. This can be a problem with disposable action pattern, because I can commit the transaction inside the Dispose() method, but in that way I will commit transaction even when the code throws an exception.&lt;/p></description></item><item><title>Retrieving long XML data from SQL without XmlReader</title><link>https://www.codewrecks.com/post/old/2008/07/retrieving-long-xml-data-from-sql-without-xmlreader/</link><pubDate>Thu, 03 Jul 2008 02:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/07/retrieving-long-xml-data-from-sql-without-xmlreader/</guid><description>&lt;p>As I told in a &lt;a href="http://www.codewrecks.com/blog/index.php/2008/05/08/get-great-amount-of-data-with-t-sql-for-xml/">previous pos&lt;/a>t if you have to retrieve a great amount of XML generated by a FOR XML in a sql server 2005 environment, you cannot use the ExecuteScalar() method of the Command object. The executeScalar in fact returns only a small amount of XML, so the right way to do this is to use XmlReader.&lt;/p>
&lt;p>Now I’m working in a project where we have the DAL written with Enterprise Library (I must admit that I do no like very much the approach of Entlib but this is another story). The concrete DAL is instantiated with IoC, but we have a generic implementation that using Entlib is capable of issuing the SQL query to different types of databases.&lt;/p></description></item><item><title>Use Sql server Publishing wizard to keep track of the change of the database structure</title><link>https://www.codewrecks.com/post/old/2008/06/use-sql-server-publishing-wizard-to-keep-track-of-the-change-of-the-database-structure/</link><pubDate>Mon, 09 Jun 2008 23:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/06/use-sql-server-publishing-wizard-to-keep-track-of-the-change-of-the-database-structure/</guid><description>&lt;p>One of the most important procedure in software development, is keeping track of every change in the project, to accomplish this task we have source control system like subversion or cvs. When you develop application that are based on a database, it is fundamental that you do not loose track of the database structure, but a source control system is not designed to keep track of database evolution. In this situation you can use the &lt;a href="http://www.microsoft.com/downloads/details.aspx?familyid=56E5B1C5-BF17-42E0-A410-371A838E570A&amp;amp;amp;displaylang=en">Sql Server Database Publishing Wizard&lt;/a> to automate a task that periodically create the script to regenerate all the database and then update the subversion to store that version. After you have installed the Sql server database publishing wizard you can create a simple bat script.&lt;/p></description></item><item><title>Get great amount of data with T-SQL for xml</title><link>https://www.codewrecks.com/post/old/2008/05/get-great-amount-of-data-with-t-sql-for-xml/</link><pubDate>Thu, 08 May 2008 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/05/get-great-amount-of-data-with-t-sql-for-xml/</guid><description>&lt;p>I’m creating some big xml files to test performance of linq to xml to make some PoC. I use simply the ForXml to extract data from Customer and Orders table of northwind database, The first Xml is 517 Kb, but I need really bigger file.&lt;/p>
&lt;p>The trick is simple I created another table called insertHelper that contain a single column, and I filled with numbers from 1 to 100:&lt;/p>
&lt;p>&lt;a href="https://www.codewrecks.com/blog/wp-content/uploads/2008/05/image1.png">&lt;a target="_blank" href="https://www.codewrecks.com/blog/wp-content/uploads/2008/05/image-thumb1.png"> &lt;img src="https://www.codewrecks.com/blog/wp-content/uploads/2008/05/image-thumb1.png" alt="image" />&lt;/a>&lt;/a>&lt;/p></description></item><item><title>About ParameterMarkerFormat</title><link>https://www.codewrecks.com/post/old/2007/09/about-parametermarkerformat/</link><pubDate>Wed, 05 Sep 2007 23:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/09/about-parametermarkerformat/</guid><description>&lt;p>Some time ago I wrote a &lt;a href="http://www.nablasoft.com/Alkampfer/?p=62">post about a generic data access&lt;/a> helper based on an article of &lt;a href="http://www.ayende.com">Ayende&lt;/a>. In that article I did a mistake in the use of ParameterMarkerFormat and I think that is time to correct it. In that article I showed a little routine to get the parameter name based on type of provider, but I used in wrong part of the code. This is the correct function AddPArameterToCommand&lt;/p></description></item><item><title>Manage conversation to a database</title><link>https://www.codewrecks.com/post/old/2007/08/manage-conversation-to-a-database/</link><pubDate>Sat, 04 Aug 2007 01:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/08/manage-conversation-to-a-database/</guid><description>&lt;p>When you begin to work with an ORM you encounter the concept of conversation, a conversation is the analogous of a transaction for database code, in a conversation I must be able to make a dialog to the ORM using the same context. In database there is no such concept, but I like it, and since sometimes I need to share nhibernate code and standard sql code in the same project I wish to be able to create a “conversation” that spans direct database access and nhibernate code. Basically a conversation has these properties&lt;/p></description></item><item><title>Sometimes it is worth to take a look at</title><link>https://www.codewrecks.com/post/old/2007/07/sometimes-it-is-worth-to-take-a-look-at/</link><pubDate>Thu, 12 Jul 2007 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/07/sometimes-it-is-worth-to-take-a-look-at/</guid><description>&lt;p>I’ve a project where I need to check every day expired records in a table. That table has a lastUpdateDate column, I simply check if the time passed from last update is greater than a given amount and for each record I must create a message for the user that owns the record, the relation is one to one, one user for each record. Moreover I do not want the user to receive a message each day, but a message even 30 days if he do not update the record, so I need to check also if a message was generated for each expired record. A couple of month ago I create a query with this structure.&lt;/p></description></item><item><title>A pattern to access DB with IDataReader</title><link>https://www.codewrecks.com/post/old/2007/06/a-pattern-to-access-db-with-idatareader/</link><pubDate>Mon, 18 Jun 2007 04:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/a-pattern-to-access-db-with-idatareader/</guid><description>&lt;p>Some days ago I &lt;a href="http://www.nablasoft.com/Alkampfer/?p=62">posted&lt;/a> about an helper class to easy the access to database. I took original code by ayende and do slightly modifications to make database indipendent. A natural extension to that class is the ability to retrieve a datareader with some data. An initial solution is simply call the core &lt;em>Execute()&lt;/em> function with this code.&lt;/p>
&lt;p>Nablasoft.Helpers.DataAccess.Execute(&lt;br>
delegate(DbCommand command, DbProviderFactory factory) {&lt;br>
command.CommandType = System.Data.CommandType.Text;&lt;br>
command.CommandText = “SELECT CompanyName FROM Customers WHERE CustomerId = @id”;&lt;br>
Nablasoft.Helpers.DataAccess.AddParameterToCommand(&lt;br>
command, factory, System.Data.DbType.String, “id”, “ANATR”);&lt;br>
//now access the datareader.&lt;br>
using(IDataReader dr = command.ExecuteReader()) {&lt;br>
Assert.IsTrue(dr.Read()); //Check if the datareader contains data.&lt;br>
Assert.AreEqual(“Ana Trujillo Emparedados y helados”, (String)dr[“CompanyName”]);&lt;br>
}&lt;br>
});&lt;/p></description></item><item><title>Overhead calling UDF in Sql server 2005</title><link>https://www.codewrecks.com/post/old/2007/06/overhead-calling-udf-in-sql-server-2005/</link><pubDate>Mon, 11 Jun 2007 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/overhead-calling-udf-in-sql-server-2005/</guid><description>&lt;p>Today I found a performance issue in a project of mine, after some try, I found that the overhead of calling a udf function is really enormous&amp;hellip;I have a query that move data from a table to another, it move about 25.000 rows, and one of the field of original table is transformed with a UDF. The query without udf runs in about 1500 ms, the query that calls udf runs in 180 minutes, even if in the UDF I simply return the parameter and do no calculation at all. Then I come across &lt;a href="http://www.novicksoftware.com/coding-in-sql/Vol3/cis-v3-N14-performannce-of-dot-net-code-sql-server-2005.htm">this post&lt;/a> that deals about this issues&amp;hellip;.so the rule is, do not use udf if you know that the udf will be called for thousands rows.&lt;/p></description></item><item><title>Improving performances in sql server when join large varchar columns</title><link>https://www.codewrecks.com/post/old/2007/06/improving-performances-in-sql-server-when-join-large-table/</link><pubDate>Mon, 04 Jun 2007 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/improving-performances-in-sql-server-when-join-large-table/</guid><description>&lt;p>I have a database with a table that contains a column called pageData of type nvarchar(3000), my problem is that periodically I need to check another db that have a similar table and I need to make a join between the two tables on pageData column. The problem is that a column of nvarchar(3000) cannot be indexed, so the join is too slow.&lt;/p>
&lt;p>A possible solution is to include a extended stored procedure to compute the Md5 of a string, apossible approach can be found &lt;a href="http://www.codeproject.com/database/xp_md5.asp">here&lt;/a>. Before joining the two table I compute the md5 value of column pageData in another column that now is indexed because is a char(32) type, and then make the join. The result is much faster than the older join.&lt;/p></description></item><item><title>When sql compare creates anger</title><link>https://www.codewrecks.com/post/old/2007/05/when-sql-compare-create-anger/</link><pubDate>Thu, 03 May 2007 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/05/when-sql-compare-create-anger/</guid><description>&lt;p>I enabled session store in database in a test server, the application is ok and after some test I proceed to store the session in database even in the production site. I create a new session state database into the production server and I copy structure doing a synchronization with session state database of the test server. The application stops to work, whenever I ask for a page the server returns a blank page and nothing is showed on the browser. After investigating log files I checked that asp.net still search state database with the name of the database in temp server. The problem originates from the fact that all the stored procedures that are in session state server use three part name. Golden rule is that asp.net session store database and authentication database should be created using aspnet_regsql.exe and not with a synchronization procedure from an existing database.&lt;/p></description></item><item><title>Error synchronizing database with red gate SQL compare</title><link>https://www.codewrecks.com/post/old/2007/05/error-synchronizing-database-with-red-gate-sql-compare/</link><pubDate>Wed, 02 May 2007 01:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/05/error-synchronizing-database-with-red-gate-sql-compare/</guid><description>&lt;p>Today I was synchronizing two database with red gate sql compare, newer database has 6 more additional view, but the sync script failed with some errors. One of the view is called MatterKnowledges and the script return error “matterknowledges” already exists, even if the destination database has no such view. The problem originates from the fact that the view (SQL2000) was create with a different name and then renamed to MatterKnowledges. The solution to the problem was dropping and then recreate the view on the original database, now all works ok.&lt;/p></description></item></channel></rss>