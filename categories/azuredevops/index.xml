<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AzureDevOps on Codewrecks</title><link>https://www.codewrecks.com/categories/azuredevops/</link><description>Recent content in AzureDevOps on Codewrecks</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 21 Jun 2022 08:00:42 +0000</lastBuildDate><atom:link href="https://www.codewrecks.com/categories/azuredevops/index.xml" rel="self" type="application/rss+xml"/><item><title>Azure DevOps: Conditional variable value in pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/conditional-variable-in-pipeline/</link><pubDate>Tue, 21 Jun 2022 08:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/conditional-variable-in-pipeline/</guid><description>Let&amp;rsquo;s examine a simple situation, in Azure DevOps you do not have a way to change pipeline priority, thus, if you need to have an agent always ready for high-priority builds, you can resort using more agent Pools. Basically you have N license for pipeline, so you can create N-1 agents in the default Pool and create another pool, lets call it Fast, where you have an agent installed in a High Performance machine.</description></item><item><title>Clone a simple dashboard with API in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/api/api-clone-dashboard-azure-devops/</link><pubDate>Fri, 11 Feb 2022 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/api-clone-dashboard-azure-devops/</guid><description>If you work in Scrum, being able to visualize data on current and past Sprints is an invaluable way to keep track on team improvement. Azure DevOps allows you to create Dashboards to visualize interesting metrics, but actually you do not have a way to create Dynamic Dashboards, I.E. a Dashboard that allows you to specify a parametric query so you can, for example, change the iteration and view how the data changes.</description></item><item><title>Azure DevOps: run test in PowerShell and publish results</title><link>https://www.codewrecks.com/post/azdo/pipeline/run-test-in-powershell/</link><pubDate>Sat, 01 Jan 2022 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/run-test-in-powershell/</guid><description>Creating full build in PowerShell has lots of advantages because you can simply launch the script and having the build run in any environment. This simplifies tremendously debugging build scripts and moving Continuous Integration from one engine to other (Ex from Azure DevOps to GitHub actions).
Clearly you need to thing in advance how to integrate with your current CI engine because usually you will need to communicate information to the engine.</description></item><item><title>Pills: Pipeline decorators</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators/</link><pubDate>Sat, 20 Nov 2021 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators/</guid><description>Pipeline decorators are a really particula feature of Azure DevOps, because they allow you to specify a series of tasks that are run for EVERY pipeline in your organization, so they are rarely needed, but nevertheless they are a nice tool to know because there are situation when they are useful. Moreover, in latest Sprint 194 update they are expanded to support new functionalities, like running before or after specific tasks.</description></item><item><title>Azure DevOps Pills: Pull request template</title><link>https://www.codewrecks.com/post/azdo/pills/pull-request-template/</link><pubDate>Sun, 14 Nov 2021 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pull-request-template/</guid><description>Azure DevOps is a really big product and sometimes there are really useful features that are poorly publicized and goes under the radar. One of these is Pull Request Templates, a really useful feature that allows you to specify markdown template for your pull requests.
I do not want to go into technical details, you can find all instructions in official documentation but I&amp;rsquo;d like to point out why this feature is so useful.</description></item><item><title>Azure DevOps: Azure File copy troubleshooting</title><link>https://www.codewrecks.com/post/azdo/pipeline/azure-file-copy/</link><pubDate>Wed, 20 Oct 2021 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/azure-file-copy/</guid><description>If you need to copy files in a Azure Blob or in an Azure Virtual machine within a Azure DevOps pipeline, Azure File Copy Task is the right task to use, but sometimes you could find some problem that make it fails. In this post I&amp;rsquo;ll state some common errors I found using it and how to solve.
Wrong number of arguments, please refer to the help page on usage of this command If you specify additional command to the task you can have this error, actually I was not able to fully troubleshooting the reason, but I discovered that version 4 of the task is somewhat erratic, so it is really better using version 3 that seems to me really more stable.</description></item><item><title>Passing boolean parameters to PowerShell scripts in Azure DevOps Pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/powershell-boolean/</link><pubDate>Sun, 08 Aug 2021 20:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/powershell-boolean/</guid><description>Let&amp;rsquo;s start from the problem, I have an Azure DevOps pipeline that calls a PowerShell script and the team needs to change the pipeline allowing a boolean parameter to be passed to the PowerShell script when you queue the pipeline. The first tentative produces this error:
1 2 3 4 C:\a\_work\56\s\build.dotnet.ps1 : Cannot process argument transformation on parameter &amp;#39;forceInstallPackage&amp;#39;. Cannot convert value &amp;#34;System.String&amp;#34; to type &amp;#34;System.Boolean&amp;#34;. Boolean parameters accept only Boolean values and numbers, The original code of the pipeline is the following one.</description></item><item><title>Azure DevOps: Use specific version of java in a pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/java-requirement-sonarcloud/</link><pubDate>Mon, 26 Apr 2021 17:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/java-requirement-sonarcloud/</guid><description>I have lots of pipelines with SonarCloud analysis, and in the last months I&amp;rsquo;ve started receiving warning for an old version of Java used in pipeline. SonarCloud task scanner is gentle enough to warn you for months before dropping the support, nevertheless there is always the possibility that you forgot to update some agents so some pipeline starts failing with error
The version of Java (1.8.xxx) you have used to run this analysis is deprecated and we stopped accepting it.</description></item><item><title>Continuous integration: PowerShell way</title><link>https://www.codewrecks.com/post/azdo/pipeline/powershell-build/</link><pubDate>Sat, 17 Apr 2021 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/powershell-build/</guid><description>I&amp;rsquo;m a great fan of Azure DevOps pipelines, I use them extensively, but I also a fan of simple building strategies, not relying on some specific build engine.
For Continuous Integration, being too much dependent on a specific technology could be limiting.
I&amp;rsquo;ve started CI with many years ago with CC.NET and explored various engines, from MsBuild to Nant then Psake, cake etc. I&amp;rsquo;ve also used various CI tools, from TFS to AzureDevOps to TeamCity and others.</description></item><item><title>Execute jobs depending on changed files on commit</title><link>https://www.codewrecks.com/post/azdo/pipeline/execution-condition-file-changed/</link><pubDate>Fri, 15 Jan 2021 17:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/execution-condition-file-changed/</guid><description>Configuring a build to build each commit to constantly verify quality of code is usually a good idea, but sooner or after, in big solutions, you start filling pipeline queue. The main problem is that, when the team grows, the number of commits for each day of work increase and you start having problem in build queue. If build queue is more than one hour long, it is still acceptable, but if the queue is even more, it become clear that you should find a solution.</description></item><item><title>Authenticate to Azure DevOps private Nuget Feed</title><link>https://www.codewrecks.com/post/azdo/pipeline/nuget-feed-authenticate/</link><pubDate>Tue, 29 Dec 2020 10:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/nuget-feed-authenticate/</guid><description>When you build a project that depends on Azure DevOps hosted nuget feed, usually if the feed is on the same organization of the pipeline and you are using Nuget task, everything regarding authentication happens automatically. A really different situation arise if you are using Nuget directly from Command Line or PowerShell script. A typical situation is: everything seems to work perfectly in your machine but during pipeline run you receive 401 (unauthenticated) error or the build hangs with a message like this:</description></item><item><title>Azure DevOps: Execute GitHub code analysis in a pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/github-code-analysis/</link><pubDate>Mon, 28 Dec 2020 08:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/github-code-analysis/</guid><description>Ok, I know that many of you are questioning: Why using Azure DevOps to analyze code with CodeQL? Using GitHub actions is the preferred way to do so why bother with running in another CI? The scenario is simple, a company has everything on Azure DevOps, it wants to retain everything there but it want to be able to gain advantage from GitHub CodeQL analysis. This scenario is not so uncommon, and you have a nice GitHub guide on how to run CodeQL code scanning in your CI System.</description></item><item><title>Azure DevOps: Convert your classic pipeline in YAML</title><link>https://www.codewrecks.com/post/azdo/pipeline/convert-to-yaml/</link><pubDate>Tue, 22 Dec 2020 18:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/convert-to-yaml/</guid><description>When I teach to customer Azure DevOps pipeline, I always suggest them to avoid the classic editor and direct learn the tool using yaml pipeline; while we can agree that classic GUI based editor is simpler, it also miss many of the advantages of YAML and have limited use.
Yaml based pipeline have a lot of advantages, first of all they are included in the code (I really love have everything in my repository), you can simple copy and paste in new projects, templates are really powerful and also your pipeline definition follow your branches.</description></item><item><title>Azure DevOps Pills: View progress in backlog</title><link>https://www.codewrecks.com/post/azdo/pills/progress-by-item/</link><pubDate>Sun, 29 Nov 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/progress-by-item/</guid><description>If you start managing your backlog with Azure Boards, you probably will end having Epics-&amp;gt;Features-&amp;gt;User stories breakdown and as manager you have a usual question to answer where are we on this epics or feature and when you expect it to be finished.
While this is not a simple question to answer looking only at the tool, you need to know that Azure Boards can give you a quick help visualizing completed work in a dedicated column.</description></item><item><title>How to handle errors in PowerShell script used in Azure DevOps pipeline</title><link>https://www.codewrecks.com/post/general/powershell/pipeline-and-powershell-return-code/</link><pubDate>Sun, 15 Nov 2020 08:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/general/powershell/pipeline-and-powershell-return-code/</guid><description>Building with PowerShell or other scripting engine is a really nice option because you can reuse the script in almost any Continuous Integration engine with a minimal effort, but sometimes there are tools that causes some headache.
I had problem with tooling like yarn and npm when they are run in Azure DevOps pipeline, the problem is that when the tool emit a warning, pipeline engine consider it an error and make the build fails.</description></item><item><title>Azure DevOps Pills: PowerShell in pipeline with Linux agents</title><link>https://www.codewrecks.com/post/azdo/pipeline/linux-powershell/</link><pubDate>Sun, 01 Nov 2020 13:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/linux-powershell/</guid><description>This is a really basic fact, but it is often underestimated. PowerShell core is now available on Linux and this means that you can use PowerShell for your Azure DevOps pipeline even if the pipeline will be executed on Linux machine. If I have this task in a pipeline
1 2 3 4 5 6 7 8 9 10 steps: - task: PowerShell@2 displayName: Simple task inputs: targetType: inline script: | Write-Host &amp;#34;Simple task for simple stage pipeline&amp;#34; Write-Host &amp;#34;Value for variable Configuration is $(configuration) value for parameterA is ${{ parameters.</description></item><item><title>Azure DevOps pills: Avoid triggering pipelines continuous integration with commit message</title><link>https://www.codewrecks.com/post/azdo/pipeline/no-ci/</link><pubDate>Sat, 24 Oct 2020 10:00:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/no-ci/</guid><description>There are situation when you need to push frequently on a Git repository, a typical example is when you are authoring a yaml pipeline and you are experimenting stuff; in such a situation you modify the pipeline, push, test and go on. It is quite common to push really frequently and this usually saturate standard pipelines.
It is not uncommon to have a standard pipeline of build and test running for each commit and for each branch.</description></item><item><title>Azure DevOps Pills: Update java in agent machines if you use SonarCloud integration</title><link>https://www.codewrecks.com/post/azdo/pills/update-java-for-sonarcloud-agents/</link><pubDate>Sat, 12 Sep 2020 12:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/update-java-for-sonarcloud-agents/</guid><description>If you have Azure DevOps pipelines that uses SonarCloud analyzer, you should update java version for your agents if you are using version 8 because support is going to drop.
Figure 1: Warning message for old java version installed
You have not many days left to solve this issue before your builds starts failing because Sonar Cloud analyzer will no longer work. The solution is simple, you can simply download an updated version of Open JDK in all agent machines.</description></item><item><title>Azure DevOps Pills: Integration with SonarCloud</title><link>https://www.codewrecks.com/post/azdo/pills/sonarcloud-integration/</link><pubDate>Thu, 20 Aug 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/sonarcloud-integration/</guid><description>I&amp;rsquo;ve dealt in the past on how to integrate SonarCloud analysis in a TFS/AzDo pipeline but today it is time to update that post with some interesting nice capabilities.
If you look in Figure 1 you can see that now SonarCloud has a direct integration with Azure DevOps pull requests, all you need to do is add a Personal Access Token with code access privilege and you are ready to go.</description></item><item><title>Azure DevOps Pills: Process rules for state transition</title><link>https://www.codewrecks.com/post/azdo/pills/state-rules/</link><pubDate>Wed, 19 Aug 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/state-rules/</guid><description>One of the most requested feature for Azure DevOps is the ability to restrict state transition for custom processes. Whenever a company starts creating its own process, Work Item States is always a big area of discussions. Which state we need? Who can change state from X to Y? Until few weeks ago, only if you have Azure DevOps server with old process model based on XML you can restrict transition between states.</description></item><item><title>Release a product composed by multiple projects and builds</title><link>https://www.codewrecks.com/post/azdo/pipeline/release-multiple-build/</link><pubDate>Sat, 30 May 2020 15:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/release-multiple-build/</guid><description>Situation We have a legacy project, born when Asp.Net WebForm was still a thing and Asp.NET MVC was still not released. This project grow during the years, in more that one subversion and git repositories. It was finally time to start setting some best practice in action and, to avoid complexity, we end with a single Git Repositories with six subfolders and six different solutions, each one that contains a part of the final product.</description></item><item><title>Test error but build green when test are re-run</title><link>https://www.codewrecks.com/post/azdo/pipeline/reruntest/</link><pubDate>Thu, 23 Apr 2020 19:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/reruntest/</guid><description>Suppose you have a result of an Azure DevOps Pipeline that contains this strange result: you have a clear indication that test run failed (1), but the overall build is green, both the entire build (2) and the single stage (3).
Figure 1: Confusing result of a build
In such a situation you wonder what happened, the overall build is green, but the clear indication that test run failed gives you some bad feeling that something was not really ok.</description></item></channel></rss>