<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AzureDevOps on Codewrecks</title><link>https://www.codewrecks.com/categories/azuredevops/</link><description>Recent content in AzureDevOps on Codewrecks</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sun, 02 Feb 2025 06:00:00 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/categories/azuredevops/index.xml" rel="self" type="application/rss+xml"/><item><title>Pill: Problems in Azure DevOps Pipelines due to Shallow Fetch</title><link>https://www.codewrecks.com/post/azdo/pills/shallow-fetch-pipeline/</link><pubDate>Sun, 02 Feb 2025 06:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/shallow-fetch-pipeline/</guid><description>In Azure DevOps, pipelines are a fundamental component for automating the build and release process. One of the key optimizations in these pipelines is the use of shallow fetch when cloning repositories. Unlike a full clone, which downloads the entire history of the repository, a shallow fetch retrieves only the specific commit needed for the build. This is a really welcomed feature, because repositories can contain years of history, or they can have some big file committed by error in some older commit.</description></item><item><title>Azure DevOps Pills: Hide not used features from Team Projects</title><link>https://www.codewrecks.com/post/azdo/pills/hide-not-used-feature/</link><pubDate>Tue, 21 Jan 2025 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/hide-not-used-feature/</guid><description>Azure DevOps is a really complete set of functionalities to manage your Development Team and more. As you can see from Figure 1, it has five main Macro Set of Features that you can use. All these features are visible in the five icons in the lower right part of the card of each Team Project
Figure 1: AzDo five main features blocks
The very same five macro Feature set is visible on the left menu when you work with the detail of the Team Project.</description></item><item><title>Azure DevOps Pills: Differences between old and new release pipeline</title><link>https://www.codewrecks.com/post/azdo/pills/release-new-and-old/</link><pubDate>Sun, 05 Jan 2025 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/release-new-and-old/</guid><description>Happy New Year to everyone. Today I&amp;rsquo;ll deal with a common question I got from customer regarding Azure DevOps release pipeline. The problem arise because we already had a GUI based pipeline in the past and then we had a fully YAML pipeline so people are somewhat puzzled on which one to use in their scenario.
When you have two way to do the same thing you are often confused on which tool to use to reach your goal</description></item><item><title>Azure DevOps Pills: Cleanup on premise pipeline agents</title><link>https://www.codewrecks.com/post/azdo/pills/cleanup-build-agent/</link><pubDate>Mon, 02 Dec 2024 08:00:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/cleanup-build-agent/</guid><description>Managing pipeline/build agents is something that you should avoid if possible, preferring docker based agents or Microsoft hosted agents. Sometimes this is not a viable options, especially if you have lots of integration tests, that runs on mongodb/elasticsearch/etc etc. While it is quite simple to create a pipeline that uses docker to run these prerequisites speed is sometimes a problem that makes this solution not so feasible.
Azure DevOps has a cost for pipeline that is based on concurrent execution, so it is quite important that pipelines run fast to use less license but, more important, to give a quick feedback to the team.</description></item><item><title>Pills: Accessing your Git Repositories in Azure DevOps in Linux</title><link>https://www.codewrecks.com/post/azdo/pills/accessing-git-from-linux/</link><pubDate>Mon, 18 Nov 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/accessing-git-from-linux/</guid><description>When you need to access your Git Repositories hosted on Azure DevOps in Linux, you have basically two distinct options.
The first one is the classic ssh protocol, that is well know to everyone working with linux systems.
Figure 1: Choosing SSH as protocol to clone from Azure DevOps
This is the preferred way to access from linux system but sadly, Azure DevOps still not support Hardware Key based SSh keys, so you are limited to use standard RSA keys as you can see in Figure 2.</description></item><item><title>Pill: Unable to change Work Item type in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/pills/unable-change-type/</link><pubDate>Wed, 13 Nov 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/unable-change-type/</guid><description>Today I got a strange error in Azure DevOps, I create a new Product Backlog Item, while I was writing it I realized that it would be better to create a Bug Type. My natural reaction was, save and then use the Change Type command, but I got this error.
Figure 1: Error Changing a Work Item Type
Work item type(s) cannot be moved because it is disabled, hidden or not supported.</description></item><item><title>Pills: Connect Azdo to external software</title><link>https://www.codewrecks.com/post/azdo/pills/connect-azdo-to-external-software/</link><pubDate>Mon, 21 Oct 2024 06:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/connect-azdo-to-external-software/</guid><description>In our team, everything regarding developing is kept in Azure DevOps, but other informations are stored inside a custom software, so we often have the need to jump between a system and the other one. The actual connection is, one element in our software is bound to one or more Work Items in Azure DevOps.
Desired result is: Ability to easily create a connection between the two, reduce the need to jump between the two system to see key information.</description></item><item><title>Azure DevOps: Cleanup Docker images for your Pull Requests</title><link>https://www.codewrecks.com/post/azdo/pipeline/clean-docker-images-for-your-pull-requests/</link><pubDate>Tue, 09 Jul 2024 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/clean-docker-images-for-your-pull-requests/</guid><description>This article is a prosecution of the previous one on creating Docker Images for your Pull Requests and deals with cleanup of your Docker Registry.
Authentication to Azure In Azure DevOps you can use connected services to connect to Azure Accounts or external services, but since I&amp;rsquo;m using mainly PowerShell scripts inside my repository, I often prefer using a Service Principal. This is a good practice because you can limit the access of the service principal to only the resources it needs to access, and you can revoke the access at any time.</description></item><item><title>Azure DevOps: Create Docker images for a Pull Request</title><link>https://www.codewrecks.com/post/azdo/pipeline/build-and-create-docker-for-your-pr/</link><pubDate>Sun, 07 Jul 2024 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/build-and-create-docker-for-your-pr/</guid><description>The whole Pull Request process mechanism has a single purpose, have a better quality of the code that reach develop or generally speaking main branch. The ability to share the code and being able to get feedback from other members of the team is invaluable, but it is enough?
The basic concept is: develop is a branch that should be considered production and it is not uncommon for teams to deploy develop branch automatically in internal production servers, a procedure called dogfooding.</description></item><item><title>Azure DevOps: Package source mapping in pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/package-sources-mapping-and-pipeline/</link><pubDate>Tue, 21 May 2024 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/package-sources-mapping-and-pipeline/</guid><description>If you use more than one Nuget Feed in your solution and especially if you are using central package versioning, you probably got a warning telling you to use Package Source Mapping. The process is straightforward, it consist in modifying your nuget.config file to specify for each package the source feed where nuget can find the package.
Here is an example for a solution I&amp;rsquo;m working:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 &amp;lt;?</description></item><item><title>Pill: Create an environment in an AzDo pipeline</title><link>https://www.codewrecks.com/post/azdo/pills/create-environment-on-pipeline/</link><pubDate>Tue, 19 Mar 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/create-environment-on-pipeline/</guid><description>Scenario: We have to create a new environment for a new customer, and an environment consists of some resources on Azure, plus an environment in azure DevOps to use with deploy pipeline. Since we are deploying with Azure DevOps pipeline, it makes sense to create everything for new customer environment with another pipeline.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 stages: - stage: create_environment jobs: - job: create_environment displayName: &amp;#34;Create environment if not present&amp;#34; pool: vmImage: windows-latest steps: - powershell: | write-Host &amp;#34;We are about to create the environment with api if not present&amp;#34; # Need to create the token in basic auth $AuthHeaders = @{ &amp;#34;Authorization&amp;#34; = &amp;#39;Basic &amp;#39; + [Convert]::ToBase64String([Text.</description></item><item><title>Pills: Enhancing Azure DevOps WorkItems with Hyperlinking to External Documentation</title><link>https://www.codewrecks.com/post/azdo/pills/use-hyperlink-link-type/</link><pubDate>Tue, 12 Mar 2024 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/use-hyperlink-link-type/</guid><description>A frequently overlooked feature that can significantly enhance functionality in Azure DevOps is the ability to attach links to a WorkItem. A common question among users is: &amp;ldquo;Can I manage documentation in tools like SharePoint and then easily link it to my project in Azure DevOps?&amp;rdquo; This query arises because there&amp;rsquo;s often a limitation on how much text can be written directly into a WorkItem, and it&amp;rsquo;s convenient to attach documentation.</description></item><item><title>Pills: What to do when dotnet restore failed with 401 against an internal feed</title><link>https://www.codewrecks.com/post/azdo/pills/problem-using-internal-nuget-feed-by-powershell/</link><pubDate>Fri, 23 Feb 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/problem-using-internal-nuget-feed-by-powershell/</guid><description>This is an argument I&amp;rsquo;ve already discussed in the past in A post about nuget authentication. From a couple of days, in a project I&amp;rsquo;m working into the service started to return 401 even with the technique described in the aforementioned post.
The sympthom is this error in the script that executed dotnet restore command.
Unable to load the service index for source https://pkgs.dev.azure.com/organizaion/_packaging/FeedName@Local/nuget/v3/index.json. Response status code does not indicate success: 401 In such a situation here is what you need to do to try to solve the problem.</description></item><item><title>Azure Devops Api - Update list of allowed values for Custom Fields</title><link>https://www.codewrecks.com/post/azdo/api/manage-custom-field-with-api/</link><pubDate>Thu, 22 Feb 2024 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/manage-custom-field-with-api/</guid><description>The ability to customize process of Azure DevOps is one of the most powerful feature of the platform. Usually you add custom fields to work items to allow tracking information related to your own process and for your organization. One of the most common question I got usually is:
How can I create a field that allows for a series of values that is taken from a database of mine?</description></item><item><title>Pills: Exploring Agent Options in Azure DevOps Pipelines: Managed vs. Self-Hosted</title><link>https://www.codewrecks.com/post/azdo/pills/do-i-need-to-deploy-my-agents/</link><pubDate>Thu, 01 Feb 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/do-i-need-to-deploy-my-agents/</guid><description>When configuring Azure DevOps pipelines, developers have a choice to make regarding the execution environment for their pipelines: they can either leverage Microsoft-managed agents provided in Azure or opt to self-host agents on their own infrastructure, whether that be on-premises virtual machines or cloud-based instances. One of the first question that arise is: which I need to use for my organization? Let&amp;rsquo;s explore the pro and cons of each option.</description></item><item><title>Pills: Do not miss repository policies in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/pills/repository-policies-for-branches/</link><pubDate>Fri, 19 Jan 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/repository-policies-for-branches/</guid><description>If you use Azure DevOps, it&amp;rsquo;s worth checking in repository settings page all the settings related to the policies of the repository itself. This is because often this type of setting is completely ignored, and you lose the opportunity to have very important controls on the repository itself.
As you can see in Figure 1, there are many interesting policies that can help your team to keep a nice and healty repository.</description></item><item><title>Pill: Include files in your publish profile for C# projects</title><link>https://www.codewrecks.com/post/azdo/pills/msbuild-copy-file/</link><pubDate>Tue, 16 Jan 2024 08:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/msbuild-copy-file/</guid><description>When publishing an ASP.NET core web project, it&amp;rsquo;s often necessary to include certain files external to the Visual Studio solution but that are logical part of the project. A typical example is frontend build from angular projects. For web projects, it&amp;rsquo;s also common to include some static resources that might be outside of the web project, like images or files.
At this point, we want the Azure DevOps pipeline to correctly include all these external files in the final artifacts.</description></item><item><title>Pill: Enhancing DevOps with Automated Pull Requests</title><link>https://www.codewrecks.com/post/azdo/pills/automatic-pull-request-close/</link><pubDate>Fri, 12 Jan 2024 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/automatic-pull-request-close/</guid><description>Pull requests are a cornerstone of collaborative software development, particularly with distributed version control systems like Git and platforms such as GitHub or Azure DevOps. However, managing pull requests can become cumbersome, particularly for branches undergoing extensive modifications and receiving frequent feedback. This complexity is evident when preparing a pull request only to find it needs additional changes due to peer review, necessitating a complete retest of the code.
Such workflows highlight the challenges in finalizing a branch.</description></item><item><title>Resolving .NET8 SDK Resolver Failure in Azure DevOps Pipelines</title><link>https://www.codewrecks.com/post/azdo/pills/strange-error-building-net8/</link><pubDate>Fri, 05 Jan 2024 07:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/strange-error-building-net8/</guid><description>I encountered a problem with a simple pipeline designed for building a .NET Core project, which I had recently updated to .NET8. After updating the pipeline file to use the new version of the SDK, I faced an unexpected issue: all builds started failing with this error.
##[error]src\Intranet\Jarvis.Common.Shared\Jarvis.Common.Shared.csproj(0,0): Error MSB4242: SDK Resolver Failure: &amp;#34;The SDK resolver &amp;#39;Microsoft.DotNet.MSBuildSdkResolver&amp;#39; failed while attempting to resolve the SDK &amp;#39;Microsoft.NET.Sdk&amp;#39;. Exception: &amp;#39;Microsoft.NET.Sdk.WorkloadManifestReader.WorkloadManifestCompositionException: Manifest provider Microsoft.NET.Sdk.WorkloadManifestReader.SdkDirectoryWorkloadManifestProvider returned a duplicate manifest ID &amp;#39;16.</description></item><item><title>Streamlining Cloud Deployment: Azure DevOps and AWS Integration Strategies</title><link>https://www.codewrecks.com/post/azdo/pipeline/deploy-in-s3-in-aws/</link><pubDate>Thu, 14 Dec 2023 08:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/deploy-in-s3-in-aws/</guid><description>Let&amp;rsquo;s assume we need to deploy in a cloud environment and prefer not to install an agent on each physical environment. For example, managing numerous agents across multiple virtual machines becomes cumbersome from an Azure DevOps standpoint. While we can surely create an environment for each distinct installation, usually this create some burden administrating the agents.
In such a scenario, the optimal approach is to create simple PowerShell or Bash installation scripts that will be distributed along pipeline artifacts.</description></item><item><title>Running GitVersion in Azure DevOps pipeline with dontet tool</title><link>https://www.codewrecks.com/post/azdo/pipeline/gitversion-powershell/</link><pubDate>Mon, 11 Dec 2023 10:00:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/gitversion-powershell/</guid><description>For me, running GitVersion as part of a Pipeline is a golden standard. I barely remember a pipeline that does not use GitVersion as first task. The reason is simple, it allows me, at least, to give a better naming to build names. Instead of having meaningless date base number I have a semantic build that immediately gives me the idea of what was built.
At least GitVersion can give a better name to a build, so why not using it?</description></item><item><title>Azure DevOps: Checkout specific branch to avoid gitversion errors in pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/checkout-code-in-build-pipeline/</link><pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/checkout-code-in-build-pipeline/</guid><description>If you create a new Azure DevOps Pipeline and include running GitVersion, sometimes you may encounter an error like the following:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 INFO [11/15/23 19:00:57:95] Begin: Calculating base versions INFO [11/15/23 19:00:57:96] Begin: Attempting to inherit branch configuration from parent branch INFO [11/15/23 19:00:57:97] End: Attempting to inherit branch configuration from parent branch (Took: 3.</description></item><item><title>Azure DevOps: Script Caching in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/pipeline/release-on-linux-cached-script/</link><pubDate>Mon, 30 Oct 2023 08:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/release-on-linux-cached-script/</guid><description>I&amp;rsquo;m authoring a release pipeline in Azure DevOps on an AWS ARM linux machine, I&amp;rsquo;ve installed the agent and created the script. The pipeline uses artifacts produced by another build pipeline and depends on a git repository that contains script. Here is how resources are declared in the pipeline.
1 2 3 4 5 6 7 8 9 10 11 12 resources: pipelines: - pipeline: UniqueHost source: Publish-UniqueHost branch: master repositories: - repository: JarvisSetupScripts type: git ref: feature/AWS name: JarvisSetupScripts Usually the question is: why you store scripts in another repository?</description></item><item><title>Pills: Install release agent in ARM machines</title><link>https://www.codewrecks.com/post/azdo/pills/installing-release-agent-in-arm-machine/</link><pubDate>Fri, 27 Oct 2023 09:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/installing-release-agent-in-arm-machine/</guid><description>With Azure Devops Environments you can register Virtual Machines with a dedicated agent that is capable of releasing your software. The procedure is simple, just create an environment, and a VM resource, and you are greeted with a minimal UI that let you choose configuration.
Figure 1: Configuring an agent for Azure DevOps environment
As you can see it just require you to select the operating system then you can copy in clipboard a simple script that you can execute in all machines you want to add in an environment.</description></item><item><title>Azure DevOps: delete all unstable version of packages in feeds</title><link>https://www.codewrecks.com/post/azdo/misc/clean-artifacts-feed/</link><pubDate>Fri, 08 Sep 2023 08:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/misc/clean-artifacts-feed/</guid><description>Azure DevOps has a dedicated section for artifacts that allows you to store NuGet, NPM feeds, and more. Thanks to its integration with pipelines, very often, automatic pipelines are generated that publish packages with every commit in the repository. This way, we have the opportunity to have all versions for all dev branches.
This approach is needed because the usual flow when you develop a new feature in a package is the following:</description></item><item><title>Modifying Azure DevOps Pipeline Decorators with Bing Chatbot Assistance</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators-on-different-os/</link><pubDate>Tue, 29 Aug 2023 16:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators-on-different-os/</guid><description>In the past, I&amp;rsquo;ve discussed using pipeline decorators to clean up build folders. Recently, I faced a challenge where I needed to modify my decorator to run only if there was a .git folder. To save time, I used Bing Chatbot, which leverages GPT powerful LLM and can search the internet to find latest contents, making this kind of problem-solving a breeze.
Figure 1: sample prompt asking to modify a piece of an Azure Devops pipeline</description></item><item><title>Azure Pipelines starts failing indexing symbols</title><link>https://www.codewrecks.com/post/azdo/pipeline/index-symbols-suddently-failing/</link><pubDate>Mon, 31 Jul 2023 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/index-symbols-suddently-failing/</guid><description>A build in Azure Devops recently started to fail during the index symbol task. The error wasn&amp;rsquo;t immediately clear. The error messages are really not informative, One such message was, &amp;ldquo;Request ed7b95f6b6f439e769a3e85422b7172be872403388fae1974fb4233dfd13da66 is sealed. Only expirationDate may be modified.&amp;rdquo;
Honestly, this error didn&amp;rsquo;t tell me much. My general advice when facing such perplexing errors is to examine the entire log. Given the vast size of the log, it&amp;rsquo;s wise to start with the most common areas where useful information can be found.</description></item><item><title>Pills: Azure Devops auto agents update</title><link>https://www.codewrecks.com/post/azdo/pills/auto-update-agents/</link><pubDate>Tue, 18 Jul 2023 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/auto-update-agents/</guid><description>The ability to update Azure DevOps pipelines is a compelling feature, especially if you manage numerous on-premise agents. This feature eliminates maintenance issues by allowing all agents to be upgraded with just a single click.
Figure 1: One click update button
I have an agent that runs only when needed, and it&amp;rsquo;s slightly outdated. By simply clicking a button, I can prompt the server to update all the agents, and I&amp;rsquo;m sure that after seconds I&amp;rsquo;m running latest agent version.</description></item><item><title>Pills: npm private feeds and authentication</title><link>https://www.codewrecks.com/post/azdo/pills/vsts-npm-auth-problems/</link><pubDate>Wed, 17 May 2023 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/vsts-npm-auth-problems/</guid><description>Have you ever encountered an issue obtaining an authentication token for your Azure DevOps npm package feed? Sometimes I got this
1 2 3 vsts-npm-auth v0.42.1.0 ----------------------- Couldn&amp;#39;t get an authentication token for https://pkgs.dev.azure.com/prxm/_packaging/JarvisNpmGood/npm/registry/. Private package feeds in Azure DevOps are incredibly useful, not just for Nuget packages, but for NPM as well. However you must follow the given instructions on the site to connect to your feed, and there will be times when you have to renew credentials.</description></item><item><title>Pills: Maximizing the Power of Tags in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/pills/azdo-tags/</link><pubDate>Mon, 08 May 2023 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/azdo-tags/</guid><description>In Azure DevOps, using tags allows you to easily classify work items. Rather than using additional process fields, tags offer a high level of classification ease because any team member can add a label to a work item.
In effect, the result is the ability to create a horizontal taxonomy that&amp;rsquo;s common to all work items and likely common to all team projects, enabling efficient filtering and categorization of Work Items.</description></item><item><title>Simplifying Library Debugging with Azure DevOps Symbol Server</title><link>https://www.codewrecks.com/post/azdo/pipeline/streamline-library-debugging/</link><pubDate>Tue, 21 Mar 2023 08:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/streamline-library-debugging/</guid><description>When developing a code library, it is good practice to publish it on a package manager like NuGet. A common objection to this approach is that using a library published as a package can make it difficult to debug the original code. However, this is not a significant issue as it encourages you to write unit tests within the same project in which you develop your library, ensuring that the library is well-tested and free of regressions.</description></item><item><title>More secure Azure DevOps Pipelines API connection thanks to OAuth Tokens</title><link>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-use-oauth2-tokens/</link><pubDate>Sun, 19 Mar 2023 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-use-oauth2-tokens/</guid><description>In a previous blog post, I discussed how to reschedule the check of a pull request using a simple PowerShell script within an Azure DevOps pipeline. This time, I&amp;rsquo;ll explain how to avoid using Personal Access Tokens for authentication and switch to a more secure alternative.
The issue with Personal Access Tokens is that they are bearer token, which means if they&amp;rsquo;re lost or accidentally leaked in logs, anyone with access to the token can use it to access your services.</description></item><item><title>Azure Devops Api - Automatically Re-Queue Pull Request Checks</title><link>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-with-pipeline/</link><pubDate>Tue, 07 Mar 2023 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-with-pipeline/</guid><description>In previous post on this subject Reschedule PR Check with API I&amp;rsquo;ve demonstrated a simple PowerShell api script that can automatically re-queue all checks for Opened pull Requests where the check is expired. The problem is: you need to schedule this script to run.
Actually the easiest way to schedule running a script that uses API is using a standard pipeline. Give the ability to run whenever the target branch changes it is the best choice.</description></item><item><title>Azure Devops Api - Re-Queue Pull Request Checks</title><link>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-with-api/</link><pubDate>Tue, 21 Feb 2023 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/reschedule-pr-check-with-api/</guid><description>Pull Requests checks are a perfect gate to keep your code quality High. The easiest way to perform a check is to do something inside a standard pipeline and then use that pipeline in branch policies. This will allow you to prevent people to push on the main develop branch (main/master/develop) and be forced to do a pull request against that branch and wait for the checks to complete.
Remember that checks on a Pull Request actually runs on the result of the merge between source and target branch.</description></item><item><title>Azure DevOps: pipeline permission to use an agent pool</title><link>https://www.codewrecks.com/post/azdo/pipeline/pipeline-permissions-agent-pool/</link><pubDate>Wed, 25 Jan 2023 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/pipeline-permissions-agent-pool/</guid><description>Scenario: We created a new Agent Pool in Azure DevOps called &amp;ldquo;linux&amp;rdquo; and we added some docker based agents, and finally we add this new pool into the available pool for a couple of builds. To verify that agents can indeed run the builds we scheduled run onto this new pool but pipeline execution failed. The error is depicted in Figure 1
Figure 1: Failed build details after changing pool to linux</description></item><item><title>Pills: Conditional Pipeline decorators</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators-conditional/</link><pubDate>Tue, 17 Jan 2023 00:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators-conditional/</guid><description>Pipeline decorators are a really peculiar feature of Azure DevOps, because they allow you to specify a series of tasks that are run for EVERY pipeline in your organization, so they are rarely needed, but nevertheless they are a nice tool to know because there are situation when they are useful. Moreover, in latest Sprint 194 update they are expanded to support new functionalities, like running before or after specific tasks.</description></item><item><title>Pills: Backup your Azure DevOps server</title><link>https://www.codewrecks.com/post/azdo/pills/backup-your-azure-devops-server/</link><pubDate>Sat, 31 Dec 2022 07:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/backup-your-azure-devops-server/</guid><description>Some days ago I got a call from a friend at customer site that experiences some problems with Azure DevOps server. The symptoms are strange server starts to become unresponsive, it is not possible even to login with Remote Desktop, it seems that there is some memory problem.
Being unable to diagnose by telephone the problem I suggest them to disable search services, sometimes it can happen that elastic search services consumes too much ram, since I did not have any other data, I suggests rebooting the machine forcibly from virtualization system and immediately connect with remote destop and disable elastic search service then try to better diagnose the problem.</description></item><item><title>Azure DevOps: check typescript linting for a Pull Request</title><link>https://www.codewrecks.com/post/azdo/pipeline/pipeline-check-lint/</link><pubDate>Fri, 30 Dec 2022 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/pipeline-check-lint/</guid><description>Pull Requests is the moment when new code undergo formal review to verify that it mets the basic quality requirement decided by the team. Most of the work can be done automatically, thanks to Azure DevcOps pipeline and various tools.
Some of the checks can be fully automated by special addin, like integration with SonarCloud so you basically does not need to do anything and you have some nice checks done to new code during PR.</description></item><item><title>Pills: Azure Devops pipeline Counters</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-counters/</link><pubDate>Wed, 21 Dec 2022 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-counters/</guid><description>Sometimes you need to have a unique number in your pipeline, usually this is needed to generate a unique version number as an example for publishing NuGet packages and avoid conflict. If you use Git (and there is no need to not use it) you can use GitVersion to generate a unique semver version number that is unique for each build. But if you are not using Git and GitVersion, or if you need to rebuild the same commit and have a unique version for each run, regardless of the commit you can use a Counter.</description></item><item><title>Pills: Azure Devops pipeline demands</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-demands/</link><pubDate>Mon, 19 Dec 2022 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-demands/</guid><description>Situation: You are waiting a pipeline to run, you view at the agent pool queue and notice that some of the agents are in idle, they are not running any pipeline, yet you have run that are waiting in queue.
You can have basically two reasons: the first one is you reached maximum number of parallel pipeline that can run on the pool, the second one is that the pipeline has some demands that are not satisfied by idle agents.</description></item><item><title>Azure DevOps Server: restart upgrade wizard</title><link>https://www.codewrecks.com/post/azdo/misc/restart-upgrade-wizard-azure-devops-server/</link><pubDate>Fri, 16 Dec 2022 06:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/misc/restart-upgrade-wizard-azure-devops-server/</guid><description>There are lots of reason why you have an on-premise installation of Azure DevOps, and if you manage it, you must devote some time to keep it upgraded to the latest version.
Keep your Azure DevOps server instance up to date constantly to avoid too big updates.
Upgrade procedures are really simple, you just launch the setup.exe from the latest version and follow the wizard. Actually not every person knows that the upgrade is basically a set of steps.</description></item><item><title>Azure Devops Api - Export Work Items</title><link>https://www.codewrecks.com/post/azdo/api/api-step-2-work-item-dump/</link><pubDate>Sat, 26 Nov 2022 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/api-step-2-work-item-dump/</guid><description>One of the most common scenario where Azure DevOps API shine is exporting data into some other db/file. There can be lots of legitimate reason why you want to export data: Custom Reporting, Custom Analysis, put everything into a file/database to perform offline query on your data outside Azure DevOps interface.
In previous parts we already saw how to connect to the server and how to check if credentials are ok; if we want to interact with the various part of the server you need to get an instance of appropriate client class.</description></item><item><title>Azure Devops Api - Detect if credentials are ok</title><link>https://www.codewrecks.com/post/azdo/api/api-step-1a-connection-check/</link><pubDate>Sat, 19 Nov 2022 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/api-step-1a-connection-check/</guid><description>In previous article of the series I&amp;rsquo;ve played with Azure DevOps api connection showing how you can use a .NET 4.8 full framework application that can login to Azure DevOps with a token or with an interactive login.
When you use interactive login, usually Windows operating system will retain credentials in credentials store, this will avoid asking for credential every time the application is run. The code that perform the check is really simple, it just check if _vssConnection.</description></item><item><title>Azure Devops Api - Connection</title><link>https://www.codewrecks.com/post/azdo/api/api-step-1-connection/</link><pubDate>Sat, 05 Nov 2022 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/api-step-1-connection/</guid><description>Quite often people asks me how to interact programmatically with Azure DevOps server, main purpose is retrieving data for custom reporting but also interacting with Work Item store etc. Luckily enough, all Azure DevOps functionalities are exposed via API, so you can write small programs to automate mundane tasks and obtain what you need.
In this post I&amp;rsquo;ll show how to setup the project in .NET and how to connect to the server.</description></item><item><title>Pills: Git command line failed to authenticate against Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/pills/git-losing-credentials/</link><pubDate>Sat, 27 Aug 2022 07:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/git-losing-credentials/</guid><description>Sometimes it just happens, you issue some Git command and you found that Azure DevOps deny Authentication, and it does not prompt for new credentials, so you are just stuck not being able to access your account anymore.
Figure 1: Git authentication failure
As you can see in Figure 1, you got an Authenticaiton Failed error, and you are not prompted for new credentials. Azure DevOps uses Personal Access Token to give access to Git, and this is done with an automatic procedure triggered by command line.</description></item><item><title>Pills: Azure Devops artifacts retention policy</title><link>https://www.codewrecks.com/post/azdo/pills/artifacts-retention-policy/</link><pubDate>Mon, 08 Aug 2022 08:10:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/artifacts-retention-policy/</guid><description>When you use extensively Azure DevOps feeds, you will end with lots of small project that automatically publish packages at each build. I have projects where each commit will publish a package thanks to GitVersion that generates a unique number for each build. This will end in a situation where thousands of packages are generated and uploaded to Azure DevOps.
In Feed settings page you have a retention policy that will automatically deletes old packages but keep those ones that are recently used, to avoid removing a package that is still in use.</description></item><item><title>Azure DevOps: Conditional variable value in pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/conditional-variable-in-pipeline/</link><pubDate>Tue, 21 Jun 2022 08:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/conditional-variable-in-pipeline/</guid><description>Let&amp;rsquo;s examine a simple situation, in Azure DevOps you do not have a way to change pipeline priority, thus, if you need to have an agent always ready for high-priority builds, you can resort using more agent Pools. Basically you have N license for pipeline, so you can create N-1 agents in the default Pool and create another pool, lets call it Fast, where you have an agent installed in a High Performance machine.</description></item><item><title>Clone a simple dashboard with API in Azure DevOps</title><link>https://www.codewrecks.com/post/azdo/api/api-clone-dashboard-azure-devops/</link><pubDate>Fri, 11 Feb 2022 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/api/api-clone-dashboard-azure-devops/</guid><description>If you work in Scrum, being able to visualize data on current and past Sprints is an invaluable way to keep track on team improvement. Azure DevOps allows you to create Dashboards to visualize interesting metrics, but actually you do not have a way to create Dynamic Dashboards, I.E. a Dashboard that allows you to specify a parametric query so you can, for example, change the iteration and view how the data changes.</description></item><item><title>Azure DevOps: run test in PowerShell and publish results</title><link>https://www.codewrecks.com/post/azdo/pipeline/run-test-in-powershell/</link><pubDate>Sat, 01 Jan 2022 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/run-test-in-powershell/</guid><description>Creating full build in PowerShell has lots of advantages because you can simply launch the script and having the build run in any environment. This simplifies tremendously debugging build scripts and moving Continuous Integration from one engine to other (Ex from Azure DevOps to GitHub actions).
Clearly you need to thing in advance how to integrate with your current CI engine because usually you will need to communicate information to the engine.</description></item><item><title>Pills: Pipeline decorators</title><link>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators/</link><pubDate>Sat, 20 Nov 2021 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pipeline-decorators/</guid><description>Pipeline decorators are a really peculiar feature of Azure DevOps, because they allow you to specify a series of tasks that are run for EVERY pipeline in your organization, so they are rarely needed, but nevertheless they are a nice tool to know because there are situation when they are useful. Moreover, in latest Sprint 194 update they are expanded to support new functionalities, like running before or after specific tasks.</description></item><item><title>Azure DevOps Pills: Pull request template</title><link>https://www.codewrecks.com/post/azdo/pills/pull-request-template/</link><pubDate>Sun, 14 Nov 2021 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/pull-request-template/</guid><description>Azure DevOps is a really big product and sometimes there are really useful features that are poorly publicized and goes under the radar. One of these is Pull Request Templates, a really useful feature that allows you to specify markdown template for your pull requests.
I do not want to go into technical details, you can find all instructions in official documentation but I&amp;rsquo;d like to point out why this feature is so useful.</description></item><item><title>Azure DevOps: Azure File copy troubleshooting</title><link>https://www.codewrecks.com/post/azdo/pipeline/azure-file-copy/</link><pubDate>Wed, 20 Oct 2021 07:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/azure-file-copy/</guid><description>If you need to copy files in a Azure Blob or in an Azure Virtual machine within a Azure DevOps pipeline, Azure File Copy Task is the right task to use, but sometimes you could find some problem that make it fails. In this post I&amp;rsquo;ll state some common errors I found using it and how to solve.
Wrong number of arguments, please refer to the help page on usage of this command If you specify additional command to the task you can have this error, actually I was not able to fully troubleshooting the reason, but I discovered that version 4 of the task is somewhat erratic, so it is really better using version 3 that seems to me really more stable.</description></item><item><title>Passing boolean parameters to PowerShell scripts in Azure DevOps Pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/powershell-boolean/</link><pubDate>Sun, 08 Aug 2021 20:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/powershell-boolean/</guid><description>Let&amp;rsquo;s start from the problem, I have an Azure DevOps pipeline that calls a PowerShell script and the team needs to change the pipeline allowing a boolean parameter to be passed to the PowerShell script when you queue the pipeline. The first tentative produces this error:
1 2 3 4 C:\a\_work\56\s\build.dotnet.ps1 : Cannot process argument transformation on parameter &amp;#39;forceInstallPackage&amp;#39;. Cannot convert value &amp;#34;System.String&amp;#34; to type &amp;#34;System.Boolean&amp;#34;. Boolean parameters accept only Boolean values and numbers, The original code of the pipeline is the following one.</description></item><item><title>Azure DevOps: Use specific version of java in a pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/java-requirement-sonarcloud/</link><pubDate>Mon, 26 Apr 2021 17:00:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/java-requirement-sonarcloud/</guid><description>I have lots of pipelines with SonarCloud analysis, and in the last months I&amp;rsquo;ve started receiving warning for an old version of Java used in pipeline. SonarCloud task scanner is gentle enough to warn you for months before dropping the support, nevertheless there is always the possibility that you forgot to update some agents so some pipeline starts failing with error
The version of Java (1.8.xxx) you have used to run this analysis is deprecated and we stopped accepting it.</description></item><item><title>Continuous integration: PowerShell way</title><link>https://www.codewrecks.com/post/azdo/pipeline/powershell-build/</link><pubDate>Sat, 17 Apr 2021 07:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/powershell-build/</guid><description>I&amp;rsquo;m a great fan of Azure DevOps pipelines, I use them extensively, but I also a fan of simple building strategies, not relying on some specific build engine.
For Continuous Integration, being too much dependent on a specific technology could be limiting.
I&amp;rsquo;ve started CI with many years ago with CC.NET and explored various engines, from MsBuild to Nant then Psake, cake etc. I&amp;rsquo;ve also used various CI tools, from TFS to AzureDevOps to TeamCity and others.</description></item><item><title>Execute jobs depending on changed files on commit</title><link>https://www.codewrecks.com/post/azdo/pipeline/execution-condition-file-changed/</link><pubDate>Fri, 15 Jan 2021 17:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/execution-condition-file-changed/</guid><description>Configuring a build to build each commit to constantly verify quality of code is usually a good idea, but sooner or after, in big solutions, you start filling pipeline queue. The main problem is that, when the team grows, the number of commits for each day of work increase and you start having problem in build queue. If build queue is more than one hour long, it is still acceptable, but if the queue is even more, it become clear that you should find a solution.</description></item><item><title>Authenticate to Azure DevOps private Nuget Feed</title><link>https://www.codewrecks.com/post/azdo/pipeline/nuget-feed-authenticate/</link><pubDate>Tue, 29 Dec 2020 10:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/nuget-feed-authenticate/</guid><description>When you build a project that depends on Azure DevOps hosted nuget feed, usually if the feed is on the same organization of the pipeline and you are using Nuget task, everything regarding authentication happens automatically. A really different situation arise if you are using Nuget directly from Command Line or PowerShell script. A typical situation is: everything seems to work perfectly in your machine but during pipeline run you receive 401 (unauthenticated) error or the build hangs with a message like this:</description></item><item><title>Azure DevOps: Execute GitHub code analysis in a pipeline</title><link>https://www.codewrecks.com/post/azdo/pipeline/github-code-analysis/</link><pubDate>Mon, 28 Dec 2020 08:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/github-code-analysis/</guid><description>Ok, I know that many of you are questioning: Why using Azure DevOps to analyze code with CodeQL? Using GitHub actions is the preferred way to do so why bother with running in another CI? The scenario is simple, a company has everything on Azure DevOps, it wants to retain everything there but it want to be able to gain advantage from GitHub CodeQL analysis. This scenario is not so uncommon, and you have a nice GitHub guide on how to run CodeQL code scanning in your CI System.</description></item><item><title>Azure DevOps: Convert your classic pipeline in YAML</title><link>https://www.codewrecks.com/post/azdo/pipeline/convert-to-yaml/</link><pubDate>Tue, 22 Dec 2020 18:50:42 +0000</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/convert-to-yaml/</guid><description>When I teach to customer Azure DevOps pipeline, I always suggest them to avoid the classic editor and direct learn the tool using yaml pipeline; while we can agree that classic GUI based editor is simpler, it also miss many of the advantages of YAML and have limited use.
Yaml based pipeline have a lot of advantages, first of all they are included in the code (I really love have everything in my repository), you can simple copy and paste in new projects, templates are really powerful and also your pipeline definition follow your branches.</description></item><item><title>Azure DevOps Pills: View progress in backlog</title><link>https://www.codewrecks.com/post/azdo/pills/progress-by-item/</link><pubDate>Sun, 29 Nov 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/progress-by-item/</guid><description>If you start managing your backlog with Azure Boards, you probably will end having Epics-&amp;gt;Features-&amp;gt;User stories breakdown and as manager you have a usual question to answer where are we on this epics or feature and when you expect it to be finished.
While this is not a simple question to answer looking only at the tool, you need to know that Azure Boards can give you a quick help visualizing completed work in a dedicated column.</description></item><item><title>How to handle errors in PowerShell script used in Azure DevOps pipeline</title><link>https://www.codewrecks.com/post/general/powershell/pipeline-and-powershell-return-code/</link><pubDate>Sun, 15 Nov 2020 08:00:00 +0200</pubDate><guid>https://www.codewrecks.com/post/general/powershell/pipeline-and-powershell-return-code/</guid><description>Building with PowerShell or other scripting engine is a really nice option because you can reuse the script in almost any Continuous Integration engine with a minimal effort, but sometimes there are tools that causes some headache.
I had problem with tooling like yarn and npm when they are run in Azure DevOps pipeline, the problem is that when the tool emit a warning, pipeline engine consider it an error and make the build fails.</description></item><item><title>Azure DevOps Pills: PowerShell in pipeline with Linux agents</title><link>https://www.codewrecks.com/post/azdo/pipeline/linux-powershell/</link><pubDate>Sun, 01 Nov 2020 13:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/linux-powershell/</guid><description>This is a really basic fact, but it is often underestimated. PowerShell core is now available on Linux and this means that you can use PowerShell for your Azure DevOps pipeline even if the pipeline will be executed on Linux machine. If I have this task in a pipeline
1 2 3 4 5 6 7 8 9 10 steps: - task: PowerShell@2 displayName: Simple task inputs: targetType: inline script: | Write-Host &amp;#34;Simple task for simple stage pipeline&amp;#34; Write-Host &amp;#34;Value for variable Configuration is $(configuration) value for parameterA is ${{ parameters.</description></item><item><title>Azure DevOps pills: Avoid triggering pipelines continuous integration with commit message</title><link>https://www.codewrecks.com/post/azdo/pipeline/no-ci/</link><pubDate>Sat, 24 Oct 2020 10:00:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/no-ci/</guid><description>There are situation when you need to push frequently on a Git repository, a typical example is when you are authoring a yaml pipeline and you are experimenting stuff; in such a situation you modify the pipeline, push, test and go on. It is quite common to push really frequently and this usually saturate standard pipelines.
It is not uncommon to have a standard pipeline of build and test running for each commit and for each branch.</description></item><item><title>Azure DevOps Pills: Update java in agent machines if you use SonarCloud integration</title><link>https://www.codewrecks.com/post/azdo/pills/update-java-for-sonarcloud-agents/</link><pubDate>Sat, 12 Sep 2020 12:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/update-java-for-sonarcloud-agents/</guid><description>If you have Azure DevOps pipelines that uses SonarCloud analyzer, you should update java version for your agents if you are using version 8 because support is going to drop.
Figure 1: Warning message for old java version installed
You have not many days left to solve this issue before your builds starts failing because Sonar Cloud analyzer will no longer work. The solution is simple, you can simply download an updated version of Open JDK in all agent machines.</description></item><item><title>Azure DevOps Pills: Integration with SonarCloud</title><link>https://www.codewrecks.com/post/azdo/pills/sonarcloud-integration/</link><pubDate>Thu, 20 Aug 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/sonarcloud-integration/</guid><description>I&amp;rsquo;ve dealt in the past on how to integrate SonarCloud analysis in a TFS/AzDo pipeline but today it is time to update that post with some interesting nice capabilities.
If you look in Figure 1 you can see that now SonarCloud has a direct integration with Azure DevOps pull requests, all you need to do is add a Personal Access Token with code access privilege and you are ready to go.</description></item><item><title>Azure DevOps Pills: Process rules for state transition</title><link>https://www.codewrecks.com/post/azdo/pills/state-rules/</link><pubDate>Wed, 19 Aug 2020 08:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pills/state-rules/</guid><description>One of the most requested feature for Azure DevOps is the ability to restrict state transition for custom processes. Whenever a company starts creating its own process, Work Item States is always a big area of discussions. Which state we need? Who can change state from X to Y? Until few weeks ago, only if you have Azure DevOps server with old process model based on XML you can restrict transition between states.</description></item><item><title>Release a product composed by multiple projects and builds</title><link>https://www.codewrecks.com/post/azdo/pipeline/release-multiple-build/</link><pubDate>Sat, 30 May 2020 15:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/release-multiple-build/</guid><description>Situation We have a legacy project, born when Asp.Net WebForm was still a thing and Asp.NET MVC was still not released. This project grow during the years, in more that one subversion and git repositories. It was finally time to start setting some best practice in action and, to avoid complexity, we end with a single Git Repositories with six subfolders and six different solutions, each one that contains a part of the final product.</description></item><item><title>Test error but build green when test are re-run</title><link>https://www.codewrecks.com/post/azdo/pipeline/reruntest/</link><pubDate>Thu, 23 Apr 2020 19:12:42 +0200</pubDate><guid>https://www.codewrecks.com/post/azdo/pipeline/reruntest/</guid><description>Suppose you have a result of an Azure DevOps Pipeline that contains this strange result: you have a clear indication that test run failed (1), but the overall build is green, both the entire build (2) and the single stage (3).
Figure 1: Confusing result of a build
In such a situation you wonder what happened, the overall build is green, but the clear indication that test run failed gives you some bad feeling that something was not really ok.</description></item></channel></rss>