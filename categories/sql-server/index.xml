<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sql Server on Codewrecks</title><link>https://www.codewrecks.com/categories/sql-server/</link><description>Recent content in Sql Server on Codewrecks</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 08 Mar 2012 10:00:37 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/categories/sql-server/index.xml" rel="self" type="application/rss+xml"/><item><title>Force Sql server index usage in query</title><link>https://www.codewrecks.com/post/old/2012/03/force-sql-server-index-usage-in-query/</link><pubDate>Thu, 08 Mar 2012 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/03/force-sql-server-index-usage-in-query/</guid><description>Sometimes sql server surprises me, I have a really stupid table with seven columns and one of these columns contains great amount of text data. I need to select the minimum Id based on a date filter, and so I issued a really simple query like:
Select min(TN.Id) from TableName TN where TN.timestamp &amp;gt;= ‘20110201’
This is a really simple query, but since the table is about 15 GB due to the large amount of text stored in it, it got executed in 140 secs, so I decided to create a simple index based on timestamp and id columns, but with my great surprise, even with the index, previous query still resort to a full table scan and needs 140 secs to be executed.</description></item><item><title>Check progress of DBCC CHECKDB</title><link>https://www.codewrecks.com/post/old/2012/02/check-progress-of-dbcc-checkdb/</link><pubDate>Tue, 07 Feb 2012 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/02/check-progress-of-dbcc-checkdb/</guid><description>If you issue a DBCC CHECKDB on a big database to verify for consistency errors, it will take a long time to complete, but the Management Studio windows usually does not give you any hint about how long does it take, or a percentage progress. Luckily enough sql server has a Dynamic Management View that can solve your problem.
This is the SQL code to visualize progress of the operation</description></item><item><title>When it is time to tweak SQL Server queries</title><link>https://www.codewrecks.com/post/old/2012/01/when-it-is-time-to-tweak-sql-server-queries/</link><pubDate>Tue, 31 Jan 2012 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/01/when-it-is-time-to-tweak-sql-server-queries/</guid><description>I’ve a stored procedure with a query that runs on a quite big database, it was slow (more than one minute to run) and was optimized using a temp table. The result is that execution time dropped to ~2 secs, and since this was acceptable the optimization stopped.
After a couple of months, the query become really slow again, it got executed in ~30 secs and I started to investigate why.</description></item><item><title>Hardcore fix error in Sql Server database</title><link>https://www.codewrecks.com/post/old/2012/01/hardcore-fix-error-in-sql-server-database/</link><pubDate>Tue, 31 Jan 2012 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2012/01/hardcore-fix-error-in-sql-server-database/</guid><description>In a production Sql Server database we had some issue with the hardware, the result is that one very big database started to gave us errors on DBCC CHECKDB, the error is the following one.
Msg 8929, Level 16, State 1, Line 1 Object ID xxxxxx, index ID 1, partition ID xxxxxx, alloc unit ID xxxxx (type In-row data): Errors found in off-row data with ID xxxxxxx owned by data record identified by RID = (3:34252:4)</description></item><item><title>Why Management Studio forces you to know SQL</title><link>https://www.codewrecks.com/post/old/2011/12/why-management-studio-forces-you-to-know-sql/</link><pubDate>Wed, 28 Dec 2011 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/12/why-management-studio-forces-you-to-know-sql/</guid><description>Suppose you have a big table with about 3 GB of data in and you need to add a nullable new column on it, you can open SSMS, open the table in designer and create a new column of type Int called sclo_durationInMinutes, press save and the table gets update quite immediately.
Then you realize that the user want the duration in Minutes as a floating point number, so you open the designer, change the type of the sclo_durationInMinutes from Int to Float and press save….</description></item><item><title>Some interesting links for SQL Server 2012 data tools</title><link>https://www.codewrecks.com/post/old/2011/11/some-interesting-links-for-sql-server-2012-data-tools/</link><pubDate>Mon, 28 Nov 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/11/some-interesting-links-for-sql-server-2012-data-tools/</guid><description>I love Database Project, introduced with Visual Studio 2008, and with SQL server 2012 they will be replaced by the Data Tools (codename Juneau), so I have a couple of links to share about this argument.
In this link you can find a table that compares all the features. As you can see, actually, one of the most missed feature in my opinion is the Data Generation and Database Unit Testing support.</description></item><item><title>Trim all non-alpha character from SQL string</title><link>https://www.codewrecks.com/post/old/2011/10/trim-all-non-alpha-character-from-sql-string/</link><pubDate>Fri, 28 Oct 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/10/trim-all-non-alpha-character-from-sql-string/</guid><description>I’have a table with some dirty data, if you select it seems that everything is ok, but since it was imported from an external source, it happens that some string field actually ends with strange non alpha char.
The symptom is that I have some strange behavior on some data, then I verify what is the content of that row, so I issue a Select * from xxx where Name = ‘Azioni’ and got no result, so I select everything that contains Azioni and I found the record.</description></item><item><title>Always pay attention to uniqueness to SQL Index</title><link>https://www.codewrecks.com/post/old/2011/10/always-pay-attention-to-uniqueness-to-sql-index/</link><pubDate>Thu, 06 Oct 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/10/always-pay-attention-to-uniqueness-to-sql-index/</guid><description>I have a database with several Gigabyte of data and query performance is usually a issue, so we need to take great care of indexes and DB optimization. Since the vast majority of data access is done with NHibernate, we have also some read-only view that we use to easy the access from the views.
One of this view, have four left outer join from a main table to other four tables and we have a SELECT COUNT query that is quite slow, so we decide to understand how to optimize it.</description></item><item><title>Run SSIS package from another server in workspace</title><link>https://www.codewrecks.com/post/old/2011/08/run-ssis-package-from-another-server-in-workspace/</link><pubDate>Fri, 05 Aug 2011 12:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/08/run-ssis-package-from-another-server-in-workspace/</guid><description>Today I needed to move some SSIS packages that actually runs on the same server where the database resides, to another server dedicated to run SSIS packages. I do not have a domain and the second server is simply in the same network as the first server. I simply reconfigured a Job to run the Package from File system (as originally configured in the original server), but now I could not use Integrated Security because I&amp;rsquo;m running the SSIS package from another PC.</description></item><item><title>Sql Server Schema and scope</title><link>https://www.codewrecks.com/post/old/2011/08/sql-server-schema-and-scope/</link><pubDate>Thu, 04 Aug 2011 13:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/08/sql-server-schema-and-scope/</guid><description>This morning I spent 20 minutes completely puzzled on a stored procedure in Sql Server. This stored procedure is not too complex, it moves data incrementally on a denormalized table to speed up some searches. The concept is simple, I run a series of queries to obtain a list of the ids of modified entity since the last run of the stored, then I update those lines and insert the new ones.</description></item><item><title>Use Sql Server Query Hints with NHibernate HQL and ICriteria</title><link>https://www.codewrecks.com/post/old/2011/07/use-sql-server-query-hints-with-nhibernate-hql-and-icriteria/</link><pubDate>Sat, 23 Jul 2011 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2011/07/use-sql-server-query-hints-with-nhibernate-hql-and-icriteria/</guid><description>When you work with Big databases with many records and not uniform distribution of data into columns used for join or where conditions, you can have really bad performance problem due to Query Plan caching. I do not want to give a deep explanation of this problem, you can find information here, but I want to outline the general problem to make clear what is happening.
We can argue a lot why this problem happens in a database engine, but basically I have a really bad situation where the db stores data of multiple customers with really non uniform distribution of data (some of them have ~1000 rows for each table, others have ~100.</description></item><item><title>Visual Studio Database Edition First steps</title><link>https://www.codewrecks.com/post/old/2009/05/visual-studio-database-edition-first-steps/</link><pubDate>Wed, 27 May 2009 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/05/visual-studio-database-edition-first-steps/</guid><description>I began using Visual Studio Database Edition today, I did not used it before because I&amp;rsquo;m the only one in the team that have this edition, others developers used VS professional, but I&amp;rsquo;m the one who cares of database in this project, quite all modifications are done by myself, so I decided to create a DataBase Project.
I was amazed because in few seconds Visual Studio scanned developement database, and creates a database project where each database object is represented by a single.</description></item><item><title>Generate insert data for sql server tables</title><link>https://www.codewrecks.com/post/old/2009/03/generate-insert-data-for-sql-server-tables/</link><pubDate>Tue, 31 Mar 2009 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/03/generate-insert-data-for-sql-server-tables/</guid><description>Sometimes I need to generate insert statement, taking data from a starting database. Suppose you need to create sql installation scripts to create a database from scratch, quite often you need also to insert some initial data into some tables.
Sql server management studio does not provide a simple way to take a table and script all its content into INSERT statement, but a simple solution can be found here. This solution is really simple, it creates a stored into the database that can be used to generate data Es.</description></item><item><title>Test Drive with database</title><link>https://www.codewrecks.com/post/old/2009/01/test-drive-with-database/</link><pubDate>Tue, 20 Jan 2009 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2009/01/test-drive-with-database/</guid><description>If you need to test drive with a database you can find a lot of problems. The basics of test drive with database is using a database sandbox, and creating a series of scripts that takes the database in a well known state before the run of each test.
In my projects I use NHibernate but there are quite often also some part of the database handled with stored or accessed through a datalayer.</description></item><item><title>SqlError quotThe server encountered a stack overflow during compile timequot</title><link>https://www.codewrecks.com/post/old/2008/08/sqlerror-the-server-encountered-a-stack-overflow-during-compile-time/</link><pubDate>Tue, 05 Aug 2008 05:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/08/sqlerror-the-server-encountered-a-stack-overflow-during-compile-time/</guid><description>This morning I see from a server log this frightening error.. “The server encountered a stack overflow during compile time”. Fortunately I used elmah to log all error of the site, so I immediately find the page that gives that problem.
It turns out that in a page we used to make some query to get a list of entities that satisfies some kind of criteria, then we build a page showing all these entities.</description></item><item><title>detecting if finally block is executing for an manhandled exception</title><link>https://www.codewrecks.com/post/old/2008/07/detecting-if-finally-block-is-executing-for-an-manhandled-exception/</link><pubDate>Fri, 25 Jul 2008 00:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/07/detecting-if-finally-block-is-executing-for-an-manhandled-exception/</guid><description>DisposableAction pattern is one of the most useful I , I used it to manage transaction for a DataAccess helper. I begin a transaction with DataAccess.BeginTransaction() that returns an IDisposable object that automatically dispose the tranasction. Here is an example of a typical use
1 2 3 4 5 using (DataAccess.BeginTransaction()) { //Do whatever query you want with DataAccess DataAccess.CommitTransaction(); } This is similar to the TransactionScope of.</description></item><item><title>Retrieving long XML data from SQL without XmlReader</title><link>https://www.codewrecks.com/post/old/2008/07/retrieving-long-xml-data-from-sql-without-xmlreader/</link><pubDate>Thu, 03 Jul 2008 02:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/07/retrieving-long-xml-data-from-sql-without-xmlreader/</guid><description>As I told in a previous post if you have to retrieve a great amount of XML generated by a FOR XML in a sql server 2005 environment, you cannot use the ExecuteScalar() method of the Command object. The executeScalar in fact returns only a small amount of XML, so the right way to do this is to use XmlReader.
Now I’m working in a project where we have the DAL written with Enterprise Library (I must admit that I do no like very much the approach of Entlib but this is another story).</description></item><item><title>Use Sql server Publishing wizard to keep track of the change of the database structure</title><link>https://www.codewrecks.com/post/old/2008/06/use-sql-server-publishing-wizard-to-keep-track-of-the-change-of-the-database-structure/</link><pubDate>Mon, 09 Jun 2008 23:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/06/use-sql-server-publishing-wizard-to-keep-track-of-the-change-of-the-database-structure/</guid><description>One of the most important procedure in software development, is keeping track of every change in the project, to accomplish this task we have source control system like subversion or cvs. When you develop application that are based on a database, it is fundamental that you do not loose track of the database structure, but a source control system is not designed to keep track of database evolution. In this situation you can use the Sql Server Database Publishing Wizard to automate a task that periodically create the script to regenerate all the database and then update the subversion to store that version.</description></item><item><title>Get great amount of data with T-SQL for xml</title><link>https://www.codewrecks.com/post/old/2008/05/get-great-amount-of-data-with-t-sql-for-xml/</link><pubDate>Thu, 08 May 2008 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2008/05/get-great-amount-of-data-with-t-sql-for-xml/</guid><description>I’m creating some big xml files to test performance of linq to xml to make some PoC. I use simply the ForXml to extract data from Customer and Orders table of northwind database, The first Xml is 517 Kb, but I need really bigger file.
The trick is simple I created another table called insertHelper that contain a single column, and I filled with numbers from 1 to 100:</description></item><item><title>About ParameterMarkerFormat</title><link>https://www.codewrecks.com/post/old/2007/09/about-parametermarkerformat/</link><pubDate>Wed, 05 Sep 2007 23:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/09/about-parametermarkerformat/</guid><description>Some time ago I wrote a post about a generic data access helper based on an article of Ayende. In that article I did a mistake in the use of ParameterMarkerFormat and I think that is time to correct it. In that article I showed a little routine to get the parameter name based on type of provider, but I used in wrong part of the code. This is the correct function AddPArameterToCommand</description></item><item><title>Manage conversation to a database</title><link>https://www.codewrecks.com/post/old/2007/08/manage-conversation-to-a-database/</link><pubDate>Sat, 04 Aug 2007 01:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/08/manage-conversation-to-a-database/</guid><description>When you begin to work with an ORM you encounter the concept of conversation, a conversation is the analogous of a transaction for database code, in a conversation I must be able to make a dialog to the ORM using the same context. In database there is no such concept, but I like it, and since sometimes I need to share nhibernate code and standard sql code in the same project I wish to be able to create a “conversation” that spans direct database access and nhibernate code.</description></item><item><title>Sometimes it is worth to take a look at</title><link>https://www.codewrecks.com/post/old/2007/07/sometimes-it-is-worth-to-take-a-look-at/</link><pubDate>Thu, 12 Jul 2007 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/07/sometimes-it-is-worth-to-take-a-look-at/</guid><description>I’ve a project where I need to check every day expired records in a table. That table has a lastUpdateDate column, I simply check if the time passed from last update is greater than a given amount and for each record I must create a message for the user that owns the record, the relation is one to one, one user for each record. Moreover I do not want the user to receive a message each day, but a message even 30 days if he do not update the record, so I need to check also if a message was generated for each expired record.</description></item><item><title>A pattern to access DB with IDataReader</title><link>https://www.codewrecks.com/post/old/2007/06/a-pattern-to-access-db-with-idatareader/</link><pubDate>Mon, 18 Jun 2007 04:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/a-pattern-to-access-db-with-idatareader/</guid><description>Some days ago I posted about an helper class to easy the access to database. I took original code by ayende and do slightly modifications to make database indipendent. A natural extension to that class is the ability to retrieve a datareader with some data. An initial solution is simply call the core Execute() function with this code.
Nablasoft.Helpers.DataAccess.Execute(
delegate(DbCommand command, DbProviderFactory factory) {
command.CommandType = System.Data.CommandType.Text;
command.CommandText = “SELECT CompanyName FROM Customers WHERE CustomerId = @id”;</description></item><item><title>Overhead calling UDF in Sql server 2005</title><link>https://www.codewrecks.com/post/old/2007/06/overhead-calling-udf-in-sql-server-2005/</link><pubDate>Mon, 11 Jun 2007 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/overhead-calling-udf-in-sql-server-2005/</guid><description>Today I found a performance issue in a project of mine, after some try, I found that the overhead of calling a udf function is really enormous&amp;hellip;I have a query that move data from a table to another, it move about 25.000 rows, and one of the field of original table is transformed with a UDF. The query without udf runs in about 1500 ms, the query that calls udf runs in 180 minutes, even if in the UDF I simply return the parameter and do no calculation at all.</description></item><item><title>Improving performances in sql server when join large varchar columns</title><link>https://www.codewrecks.com/post/old/2007/06/improving-performances-in-sql-server-when-join-large-table/</link><pubDate>Mon, 04 Jun 2007 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/06/improving-performances-in-sql-server-when-join-large-table/</guid><description>I have a database with a table that contains a column called pageData of type nvarchar(3000), my problem is that periodically I need to check another db that have a similar table and I need to make a join between the two tables on pageData column. The problem is that a column of nvarchar(3000) cannot be indexed, so the join is too slow.
A possible solution is to include a extended stored procedure to compute the Md5 of a string, apossible approach can be found here.</description></item><item><title>When sql compare creates anger</title><link>https://www.codewrecks.com/post/old/2007/05/when-sql-compare-create-anger/</link><pubDate>Thu, 03 May 2007 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/05/when-sql-compare-create-anger/</guid><description>I enabled session store in database in a test server, the application is ok and after some test I proceed to store the session in database even in the production site. I create a new session state database into the production server and I copy structure doing a synchronization with session state database of the test server. The application stops to work, whenever I ask for a page the server returns a blank page and nothing is showed on the browser.</description></item><item><title>Error synchronizing database with red gate SQL compare</title><link>https://www.codewrecks.com/post/old/2007/05/error-synchronizing-database-with-red-gate-sql-compare/</link><pubDate>Wed, 02 May 2007 01:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2007/05/error-synchronizing-database-with-red-gate-sql-compare/</guid><description>Today I was synchronizing two database with red gate sql compare, newer database has 6 more additional view, but the sync script failed with some errors. One of the view is called MatterKnowledges and the script return error “matterknowledges” already exists, even if the destination database has no such view. The problem originates from the fact that the view (SQL2000) was create with a different name and then renamed to MatterKnowledges.</description></item></channel></rss>