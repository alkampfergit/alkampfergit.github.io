<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Azure DevOps on Codewrecks</title><link>https://www.codewrecks.com/categories/azure-devops/</link><description>Recent content in Azure DevOps on Codewrecks</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sat, 11 Apr 2020 06:00:37 +0200</lastBuildDate><atom:link href="https://www.codewrecks.com/categories/azure-devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Strange Error uploading artifacts in Azure DevOps pipeline</title><link>https://www.codewrecks.com/post/old/2020/04/strange-error-uploading-artifacts-in-azure-devops-pipeline/</link><pubDate>Sat, 11 Apr 2020 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/04/strange-error-uploading-artifacts-in-azure-devops-pipeline/</guid><description>I have a pipeline that worked perfectly for Years, but yesterday a build failed while uploading artifacts, I queued it again and it still failed, so it does not seems to be an intermittent error (network could be unreliable). I was really puzzled because from the last good build we changed 4 C# files, nothing really changed that can justify the failing and also we have no network problem that can justify problem uploading artifacts to Azure DevOps.</description></item><item><title>Azure DevOps Pipeline template steps and NET Core 3 local tools</title><link>https://www.codewrecks.com/post/old/2020/04/azure-devops-pipeline-template-steps-and-net-core-3-local-tools/</link><pubDate>Tue, 07 Apr 2020 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/04/azure-devops-pipeline-template-steps-and-net-core-3-local-tools/</guid><description>I’m a strong fan of Azure DevOps templates for pipelines because it is a really good feature to both simplify Pipeline authoring and avoid proliferation of too many way to do the same things. In some of my previous examples I’ve always used a template that contains full Multi Stage pipeline definition , this allows you to create a new pipeline with easy, reference repository with the template, choose right template, set parameters and you are ready to go.</description></item><item><title>Azure DevOps pipeline template for build and release NET core project</title><link>https://www.codewrecks.com/post/old/2020/03/azure-devops-pipeline-template-for-build-and-release-net-core-project/</link><pubDate>Sun, 29 Mar 2020 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/03/azure-devops-pipeline-template-for-build-and-release-net-core-project/</guid><description>Some days ago I’ve blogged on how to release projects on GitHub with actions, now it is time to understand how to do a similar thing in Azure DevOps to build / test / publish a.NET core library with nuget. The purpose is to create a generic template that can be reused on every general that needs to build an utility dll, run test and publish to a Nuget feed.</description></item><item><title>One Team Project to rule them all</title><link>https://www.codewrecks.com/post/old/2020/03/one-team-project-to-rule-them-all/</link><pubDate>Sat, 21 Mar 2020 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/03/one-team-project-to-rule-them-all/</guid><description>A similar post was made lots of time ago, but since this is always an hot topic, it is probably the time to refresh with new UI and new concepts of Azure DevOps.
The subject is, how can I apply security to backlogs if I adopt the strategy one single Team Project subdivided by teams?
The approach One Team Project to rule them all is still valid as today , because, once you have a team project, you can divide it with Teams, where each team has its own backlog (or share a single backlog between teams) making everything more manageable.</description></item><item><title>Azure DevOps YAML pipeline authorization problem</title><link>https://www.codewrecks.com/post/old/2020/03/azure-devops-yaml-pipeline-authorization-problem/</link><pubDate>Tue, 10 Mar 2020 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/03/azure-devops-yaml-pipeline-authorization-problem/</guid><description>It could happen, sometimes, that when you create a pipeline in Azure Devops at first run you got the following error.
##[error]Pipeline does not have permissions to use the referenced pool(s) Default. For authorization details, refer to https://aka.ms/yamlauthz.
There are more than one kind of this error, the most common one is the build using some external resource that requires authorization, but in this specific error message, pipeline has no permission to run on default pool.</description></item><item><title>Windows Docker Container for Azure Devops Build agent</title><link>https://www.codewrecks.com/post/old/2020/01/windows-docker-container-for-azure-devops-build-agent/</link><pubDate>Sat, 25 Jan 2020 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2020/01/windows-docker-container-for-azure-devops-build-agent/</guid><description>Thanks to Docker Compose, I can spin off an agent for Azure Devops in mere seconds (once you have all the images). Everything I need is just insert the address of my account a valid token and an agent is ready.
With.NET core everything is simple, because we have a nice build task that automatically install.NET Core SDK in the agent, the very same for node.js. This approach is really nice, because it does not require to preinstall too much stuff in your agent, everything is downloaded and installed on the fly when a build needs that specific tooling.</description></item><item><title>Consume Azure DevOps feed in TeamCity</title><link>https://www.codewrecks.com/post/old/2019/12/consume-azure-devops-feed-in-teamcity/</link><pubDate>Wed, 04 Dec 2019 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/12/consume-azure-devops-feed-in-teamcity/</guid><description>Azure DevOps has an integrated feed management you can use for nuget, npm, etc; the feed is private and only authorized users can download / upload packages. Today I had a little problem setting up a build in Team City that uses a feed in Azure Devops, because it failed with 201 (unauthorized)
The problem with Azure DevOps NuGet feeds, is how to authenticate other toolchain or build server.
This project still have some old build in TeamCity, but when it starts consuming packages published in Azure Devops, TeamCity builds start failing due 401 (unauthorized) error.</description></item><item><title>Multiline PowerShell on YAML pipeline</title><link>https://www.codewrecks.com/post/old/2019/11/multiline-powershell-on-yaml-pipeline/</link><pubDate>Tue, 19 Nov 2019 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/11/multiline-powershell-on-yaml-pipeline/</guid><description>Sometimes having a few lines of PowerShell in your pipeline is the only thing you need to quickly customize a build without using a custom task or having a PowerShell file in source code. One of the typical situation is: write a file with some content that needs to be determined by a PowerShell script, in my situation I need to create a configuration file based on some build variable.</description></item><item><title>Azure DevOps multi stage pipeline environments</title><link>https://www.codewrecks.com/post/old/2019/11/azure-devops-multi-stage-pipeline-environments/</link><pubDate>Tue, 12 Nov 2019 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/11/azure-devops-multi-stage-pipeline-environments/</guid><description>In a previous post on releasing with Multi Stage Pipeline and YAML code I briefly introduced the concept of environments. In that example I used an environment called single_env and you can be surprised that, by default, an environment is automatically created when the release runs. This happens because an environment can be seen as sets of resources used as target for deployments, but in the actual preview version, in Azure DevOps, you can only add Kubernetes resources.</description></item><item><title>Release app with Azure DevOps Multi Stage Pipeline</title><link>https://www.codewrecks.com/post/old/2019/10/release-app-with-azure-devops-multi-stage-pipeline/</link><pubDate>Mon, 21 Oct 2019 15:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/10/release-app-with-azure-devops-multi-stage-pipeline/</guid><description>MultiStage pipelines are still in preview on Azure DevOps, but it is time to experiment with real build-release pipeline, to taste the news. The Biggest limit at this moment is that you can use Multi Stage to deploy in Kubernetes or in the cloud, but there is not support for agent in VM (like standard release engine). This support will be added in the upcoming months but if you use azure or kubernetes as a target you can already use it.</description></item><item><title>Sample report for Azure DevOps</title><link>https://www.codewrecks.com/post/old/2019/08/sample-report-for-azure-devops/</link><pubDate>Mon, 19 Aug 2019 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/08/sample-report-for-azure-devops/</guid><description>Reporting was always a pain point in Azure DevOps, because people used on SQL Server reporting Services for the on-premise version, missed a similar ability to create custom reports in Azure Dev Ops.
Now you have a nice integration with Power BI and a nice article here that explains how to connect Power BI to your instance and create some basic query. The nice part is that you can use a query that will connect directly with the OData feed, no need to install anything.</description></item><item><title>Azure DevOps gems YAML Pipeline and Templates</title><link>https://www.codewrecks.com/post/old/2019/08/azure-devops-gems-yaml-pipeline-and-templates/</link><pubDate>Sun, 18 Aug 2019 05:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/08/azure-devops-gems-yaml-pipeline-and-templates/</guid><description>If you read my blog you already know that I’m a great fan of YAML Pipeline instead of using Graphic editor in the Web UI, there are lots of reasons why you should use YAML; one for all the ability to branch Pipeline definition with code, but there is another really important feature: templates.
There is a really detailed documentation on MSDN on how to use this feature, but I want to give you a complete walkthrough on how to start to effectively use templates.</description></item><item><title>Retrieve Attachment in Azure DevOps with REST API</title><link>https://www.codewrecks.com/post/old/2019/07/retrieve-attachment-in-azure-devops-with-rest-api/</link><pubDate>Thu, 25 Jul 2019 20:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/07/retrieve-attachment-in-azure-devops-with-rest-api/</guid><description>In a previous post I’ve dealt on how to retrieve image in Work Items description or Comments with a simple WebClient request, using network credentials taken from TfsTeamProjectCollection class.
The solution presented in that article is not complete, because it does not works against Azure Devops, but only against a on-premise TFS or Azure DevOps Server . If you connect to Azure DevOps you will find that the Credentials of the TfsTeamProjectCollection class are null , thus you cannot download the attachment because the web request is not authenticated.</description></item><item><title>Export Work Item Information to Word Document</title><link>https://www.codewrecks.com/post/old/2019/07/export-work-item-information-to-word-document/</link><pubDate>Thu, 25 Jul 2019 19:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/07/export-work-item-information-to-word-document/</guid><description>This is a series of posts on how to export data from Azure DevOps to a Word Document, composing word templates with Open XML Sdk.
The project is open source and available Here: https://github.com/alkampfergit/AzureDevopsWordPlayground
Post in the series:
API Connection Retrieve Work Items Information Azure DevOps API, Embed images into HTML Create Word Document For Work Items Retrieve image in Work Item Description with TFS API Retrieve Attachment in Azure DevOps with REST API in C# Gian Maria</description></item><item><title>Retrieve image in Work Item Description with TFS API</title><link>https://www.codewrecks.com/post/old/2019/07/retrieve-image-in-work-item-description-with-tfs-api/</link><pubDate>Wed, 10 Jul 2019 20:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/07/retrieve-image-in-work-item-description-with-tfs-api/</guid><description>When you try to export content of Work Item from Azure DevOps (online or server) you need to deal with external images that are referenced in HTML fields of Work Item. I’ve dealt in the past on this subject, showing how you can retrieve images with Store and Attachment Work Item Property.
Sadly enough, I’ve encountered situation with on-premise version of TFS where I found this type of image src inside HTML fields.</description></item><item><title>Install latest node version in Azure Pipelines</title><link>https://www.codewrecks.com/post/old/2019/06/install-latest-node-version-in-azure-pipelines/</link><pubDate>Wed, 12 Jun 2019 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/06/install-latest-node-version-in-azure-pipelines/</guid><description>I have a build in Azure DevOps that suddenly starts failing on some agents during the build of an angular application. Looking at the log I found that error
You are running version v8.9.4 of Node.js, which is not supported by Angular CLI 8.0+.
Ok, the error is really clear, some developer upgraded Angular version on the project and node version installed in some of the build servers is old. Now the obvious situation is logging in ALL build servers, upgrade node js installation and the build should run on every agent.</description></item><item><title>Another gem of Azure Devops multistage pipelines</title><link>https://www.codewrecks.com/post/old/2019/05/another-gem-of-azure-devops-multistage-pipelines/</link><pubDate>Sat, 18 May 2019 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/05/another-gem-of-azure-devops-multistage-pipelines/</guid><description>With deployment of Sprint 151 we have an exciting news for Azure DevOps called multi stage pipelines. If you read my blog you should already know that I’m a huge fan of having YAML build definition, but until now, for the release part, you still had to have the standard graphical editor. Thanks to Multi Stage Pipelines now you can have both build and release definition directly in a single YAML file.</description></item><item><title>Converting Existing pipeline to YAML how to avoid double builds</title><link>https://www.codewrecks.com/post/old/2019/05/converting-existing-pipeline-to-yaml-how-to-avoid-double-builds/</link><pubDate>Sat, 04 May 2019 05:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/05/converting-existing-pipeline-to-yaml-how-to-avoid-double-builds/</guid><description>Actually YAML build is the preferred way to create Azure DevOps Build Pipeline and converting existing build is really simple thanks to the “View YAML” button that can simply convert every existing pipeline in a YAML definition. figure 1: Converting existing Pipeline in YAML is easy with the View YAML button present in editor page.
The usual process is, start a new feature branch to test pipeline conversion to YAML, create the YAML file and a Pipeline based on it, then start testing.</description></item><item><title>Error publishing NET core app in Azure Devops YAML Build</title><link>https://www.codewrecks.com/post/old/2019/04/error-publishing-net-core-app-in-azure-devops-yaml-build/</link><pubDate>Tue, 30 Apr 2019 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/04/error-publishing-net-core-app-in-azure-devops-yaml-build/</guid><description>Short story, I’ve created a simple YAML build for a.NET core project where one of the task will publish a simple.NET core console application. After running the build I’ve a strange error in the output
No web project was found in the repository. Web projects are identified by presence of either a web.config file or wwwroot folder in the directory.
This is extremely strange, because the project is not a web project, it is a standard console application written for.</description></item><item><title>Azure DevOps is now 150 sprints old</title><link>https://www.codewrecks.com/post/old/2019/04/azure-devops-is-now-150-sprints-old/</link><pubDate>Fri, 19 Apr 2019 20:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/04/azure-devops-is-now-150-sprints-old/</guid><description>I remember old days when Azure DevOps was still in private preview, and yet it was really a good product, now 150 sprints passed, and the product is better than ever. Not everything is perfect, but, as users, we can expect new feature to being deployed each 3 weeks, the duration of Microsoft Sprint.
This means that now the product is 450 Weeks old, and finally we got a little nice feature that shows up news in the front page.</description></item><item><title>How to edit a YAML Azure DevOps Pipeline</title><link>https://www.codewrecks.com/post/old/2019/04/how-to-edit-a-yaml-azure-devops-pipeline/</link><pubDate>Sun, 14 Apr 2019 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/04/how-to-edit-a-yaml-azure-devops-pipeline/</guid><description>I cannot stress you enough on how better is the experience of having builds defined in code than having build definition on the server , so I’m here to convince you to move to the new YAML build system in Azure DevOps :).
Having build definition in Code gives you many benefits, the first is that builds evolve with code branches.
If you still think that editing a YAML file is a daunting experience because you have tons of possible tasks and configuration to use, take a peek to the Azure Pipeline extension Visual Studio Code Addin, that brings intellisense for your pipeline editing in Visual Studio Code.</description></item><item><title>Troubleshoot YAML Build first run</title><link>https://www.codewrecks.com/post/old/2019/04/troubleshoot-yaml-build-first-run/</link><pubDate>Sat, 13 Apr 2019 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/04/troubleshoot-yaml-build-first-run/</guid><description>Scenario : You create a branch in your git repository to start with a new shiny YAML Build definition for Azure Devops, you create a yaml file, push the branch in Azure Devops and Create a new Build based on that YAML definition. Everything seems ok, but when you press the run button you got and error
Could not find a pool with name Default. The pool does not exist or has not been authorized for use.</description></item><item><title>Build and Deploy AspNet App with Azure DevOps</title><link>https://www.codewrecks.com/post/old/2019/03/build-and-deploy-asp-net-app-with-azure-devops/</link><pubDate>Thu, 28 Mar 2019 19:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/03/build-and-deploy-asp-net-app-with-azure-devops/</guid><description>I’ve blogged in the past about deploying ASP.NET application, but lots of new feature changed in Azure DevOps and it is time to do some refresh of basic concepts. Especially in the field of web.config transform there is always lots of confusion and even if I’m an advocate of removing every configuration from files and source, it is indeed something that worth to be examined. &amp;gt; The best approach for configuration is removing then from source control, use configuration services, etc and move away from web.</description></item><item><title>YAML Build in Azure DevOps</title><link>https://www.codewrecks.com/post/old/2019/03/yaml-build-in-azure-devops/</link><pubDate>Sat, 16 Mar 2019 15:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/03/yaml-build-in-azure-devops/</guid><description>I’ve blogged in the past about YAML build in azure DevOps, but in that early days, that kind of build was a little bit rough and many people still preferred the old build based on visual editing in a browser. One of the main complaint was that the build was not easy to edit and there were some glitch, especially when it is time to access external services.
After months from the first version, the experience is really improved and I strongly suggest you to start trying to migrate existing build to this new system, to take advantage of having definition of build directly in the code, a practice that is more DevOps oriented and that allows you to have different build tasks for different branches.</description></item><item><title>Find work Items in Azure DevOps was ever operator</title><link>https://www.codewrecks.com/post/old/2019/03/find-work-items-in-azure-devops-was-ever/</link><pubDate>Thu, 07 Mar 2019 12:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/03/find-work-items-in-azure-devops-was-ever/</guid><description>Query language in Azure DevOps is really rich and sometimes people really misses its power, struggling to find and manage all work item with the standard boards. There are a lot of times in a complex project when you are not able to find a specific Work Item and you feel lost because you know that it is in the system, but you just does not know how to find id.</description></item><item><title>Is Manual Release in Azure DevOps useful</title><link>https://www.codewrecks.com/post/old/2019/02/is-manual-release-in-azure-devops-useful/</link><pubDate>Fri, 08 Feb 2019 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/02/is-manual-release-in-azure-devops-useful/</guid><description>When people creates a release in AzureDevOps, they primarily focus on how to make the release automatic , but to be 100% honest, automation in only one side of the release, and probably not the more useful.
First of all Release is about auditing and understand which version of the software is released where and by whom. In this scenario what is more important is “how I can deploy my software in production”.</description></item><item><title>WIQL editor extension For Azure DevOps</title><link>https://www.codewrecks.com/post/old/2019/02/wiql-editor-extension-for-azure-devops/</link><pubDate>Sun, 03 Feb 2019 15:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/02/wiql-editor-extension-for-azure-devops/</guid><description>One of the nice feature of Azure DevOps is extendibility, thanks to REST API you can write addins or standalone programs that interacts with the services. One of the addin that I like the most is the Work Item Query Language Editor, a nice addin that allows you to interact directly with the underling syntax of Work Item query.
Once installed, whenever you are in query Editor, you have the ability to directly edit the query with WIQL syntax, thanks to the “Edit Query wiql” menu entry.</description></item><item><title>Change Work Item Type in a fresh installation of Azure DevOps server</title><link>https://www.codewrecks.com/post/old/2019/01/change-work-item-type-in-a-fresh-installation-of-azure-devops-server/</link><pubDate>Sat, 26 Jan 2019 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/01/change-work-item-type-in-a-fresh-installation-of-azure-devops-server/</guid><description>If you want to use Azure DevOps I strongly suggest you to use cloud version https://dev.azure.com, but if you really need to have it on premise, you can install Team Foundation Server, now renamed to Azure DevOps Server.
One of the most waited feature for the on-premise version is the ability to change work item Type and to move work item between project, a feature present in Azure DevOps Server, but that needs a complete disable of Reporting Services to work, as I discussed in an old Post.</description></item><item><title>Sonar Analysis of Python with Azure DevOps pipeline</title><link>https://www.codewrecks.com/post/old/2019/01/sonar-analysis-of-python-with-azure-devops-pipeline/</link><pubDate>Sat, 05 Jan 2019 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2019/01/sonar-analysis-of-python-with-azure-devops-pipeline/</guid><description>Once you have test and Code Coverage for your build of Python code, last step for a good build is adding support for Code Analysis with Sonar/SonarCloud. SonarCloud is the best option if your code is open source, because it is free and you should not install anything except the free addin in Azure Devops Marketplace.
From original build you need only to add two steps: PrepareAnalysis onSonarCloud and Run SonarCloud analysis, in the same way you do analysis for a.</description></item><item><title>Create Word document from Work Items</title><link>https://www.codewrecks.com/post/old/2018/12/create-word-document-from-work-items/</link><pubDate>Mon, 31 Dec 2018 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/create-word-document-from-work-items/</guid><description>Post in the series:
API Connection Retrieve Work Items Information Azure DevOps API, Embed images into HTML Now we have all the prerequisites in place to connect to an Azure DevOps account, execute a query to grab all work items of a sprint and modifying HTML of Rich Edit fields to embed images. It is time to create a word document.
To have a better look and feel of exported document, the best approach is using the concept of Templates created by simple Word documents.</description></item><item><title>Azure DevOps API Embed images into html</title><link>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-embed-images-into-html/</link><pubDate>Mon, 31 Dec 2018 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-embed-images-into-html/</guid><description>Post in the series:
API Connection Retrieve Work Items Information Before going to generate a Word File from Work Item Data we need to solve a little problem with HTML content in Work Item fields. As you know Azure DevOps has a rich web editor that allows you to create complex text in some fields, like Description, the problem is: whenever you copy and paste images inside the Web Editor, those images were added as Work Item attachments and the real HTML content is just a reference to the attachmen Url.</description></item><item><title>Azure DevOps API Retrieve Work Items Information</title><link>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-retrieve-work-items-information/</link><pubDate>Fri, 28 Dec 2018 11:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-retrieve-work-items-information/</guid><description>Post in the series:
API Connection Now that we know how to connect to Azure DevOps services, it is time to understand how to retrieve information about Work Items to accomplish the requested task: export Work Items data inside a Word Document.
Once you connected to Azure DevOps account you start retrieving helper classes to work with the different functions of the service, if you need to interact with Work Items you need a reference to the WorkItemStore class.</description></item><item><title>Azure Devops API Connection</title><link>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-connection/</link><pubDate>Fri, 28 Dec 2018 10:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/azure-devops-api-connection/</guid><description>One of the great benefit of using Azure DevOps is the ability to interact with the service through API calls, making it possible to extend the service with a few bunch of C#, or PowerShell or whatever language you want, because almost everything is exposed with REST API, and a simple HTTP call is enough.
Since I’m mostly a C# and.NET guy, I’ll explain how to build a C# program that interact with an Azure DevOps account, because thanks to Nuget Packages offered by Microsoft, you can interact with your account with Strongly Typed C# classes, so you can have intellisense and compile type checking to verify that everything is good.</description></item><item><title>TFS 2019 Change Work Item Type and Move Between Team Project</title><link>https://www.codewrecks.com/post/old/2018/12/tfs-2019-change-work-item-type-and-move-between-team-project/</link><pubDate>Sun, 16 Dec 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/tfs-2019-change-work-item-type-and-move-between-team-project/</guid><description>When the first version of Team Foundation Server on Azure was presented, it has less feature than on-premise version, but actually Azure Dev Ops has changed the situation. The reality is that new features are first introduced into Azure Dev Ops, then on Azure Dev Ops Server (the on-premise version). A couple of features were really missing on the on-premise version, the ability to change Work Item Type and the ability to move Work Items between projects.</description></item><item><title>Deploy click-once application on Azure Blob with Azure DevOps</title><link>https://www.codewrecks.com/post/old/2018/12/deploy-click-once-application-on-azure-blob-with-azure-devops/</link><pubDate>Fri, 07 Dec 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/12/deploy-click-once-application-on-azure-blob-with-azure-devops/</guid><description>It was a long time ago I blogged on how to publish a click-once application from a VSTS Build to Azure Blob, long time was passed, and lots of stuff changed. The whole process is now simpler, thanks to many dedicated tasks that avoid doing any manual work.
My new build always start with a GitVersion custom tasks, that populates some environment variables with version numbers generated by GitVersion, this will allow me to simply add an MsBuild task in the build to publish click-once using automatic GitVersion versioning.</description></item><item><title>Run code coverage for Python project with Azure DevOps</title><link>https://www.codewrecks.com/post/old/2018/11/run-code-coverage-for-python-project-with-azure-devops/</link><pubDate>Tue, 20 Nov 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/11/run-code-coverage-for-python-project-with-azure-devops/</guid><description>Creating a simple build that runs Python tests written with PyTest framework is really simple, but now the next step is trying to have code coverage. Even if I’m pretty new to Python, having code coverage in a build is really simple, thanks to a specific task that comes out-of-the-box with Azure DevOps: Publish Code Coverage.
In Azure DevOps you can create build with Web Editor or with simple YAML file, I prefer YAML but since I’ve demonstrated in the old post YAML build for Python, now I’m creating a simple build with standard Web Editor</description></item><item><title>Set new Azure DevOps url for your account</title><link>https://www.codewrecks.com/post/old/2018/11/set-new-azure-devops-url-for-your-account/</link><pubDate>Tue, 20 Nov 2018 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/11/set-new-azure-devops-url-for-your-account/</guid><description>Due to switching from the old url format organization.visualstudio.com to dev.azure.com/organization it is a good practice to start transition to the new url as soon as possible. The old url will continue to function for a long time, but the new official domain is going to become the default.
Every user can still use both the new or old domain name, but there is a settings in the general setting page of the account that globally enable the new url.</description></item><item><title>Run Python test with Azure DevOps pipeline</title><link>https://www.codewrecks.com/post/old/2018/11/run-python-test-with-azure-devops-pipeline/</link><pubDate>Mon, 12 Nov 2018 22:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/11/run-python-test-with-azure-devops-pipeline/</guid><description>The beauty of Azure DevOps is it support to many technologies and all of major language.s I have a simple git repository where I’m experimenting Python code, in that repository I have several directories like 020_xxxx 010_yyy where I’m playing with Python code.
Each folder contains some code and some unit tests written in Pytest, my goal is creating an Azure Pipeline that can automatically run all pytest for me automatically each time I push some code to the repository.</description></item><item><title>Analyze your GitHub project for free with Azure DevOps and SonarCloud</title><link>https://www.codewrecks.com/post/old/2018/11/analyze-your-github-project-for-free-with-azure-devops-and-sonarcloud/</link><pubDate>Sun, 04 Nov 2018 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/11/analyze-your-github-project-for-free-with-azure-devops-and-sonarcloud/</guid><description>I’ve blogged some weeks ago on how to analyze OS code with SonarCloud, but it is time to update the post, because if you want to use SonarCloud you have a dedicated extension in the marketplace.
Figure 1: Official SonarCloud extension in the marketplace.
One of the great feature of Azure DevOps is its extendibility, that allows people external to Microsoft to create extensions to expand the possibility of the tool.</description></item><item><title>Azure DevOps pipelines and Sonar Cloud gives free analysis to your OS project</title><link>https://www.codewrecks.com/post/old/2018/10/azure-devops-pipelines-and-sonar-cloud-gives-free-analysis-to-your-os-project/</link><pubDate>Wed, 10 Oct 2018 21:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/10/azure-devops-pipelines-and-sonar-cloud-gives-free-analysis-to-your-os-project/</guid><description>In previous post I’ve shown how easy is to create a YAML definition to create a build definition to build your GitHub Open Source project in Azure DevOps, without the need to spend any money nor installing anything on you server.
Once you create a default build that compile and run tests, it would be super nice to create a free account in SonarCloud to have your project code to be analyzed automatically from the Azure Pipeline you’ve just created.</description></item><item><title>Code in GitHub Build in Azure DevOps and for FREE</title><link>https://www.codewrecks.com/post/old/2018/10/code-in-github-build-in-azure-devops-and-for-free/</link><pubDate>Tue, 09 Oct 2018 21:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/10/code-in-github-build-in-azure-devops-and-for-free/</guid><description>When you create a new open source project in GitHub, one of the first step is to setup continuous integration; the usual question is: What CI engine should I use? Thanks to Azure Dev Ops, you can use free build pipelines to build projects even if they are in GitHub (not hosted in Azure Dev Ops)
Azure Dev Ops, formerly known as VSTS, allows to define free build pipelines to build projects in GitHub</description></item><item><title>VSTS Name change in Azure DevOps effects on Git repositories</title><link>https://www.codewrecks.com/post/old/2018/09/vsts-name-change-in-azure-devops-effects-on-git-repositories/</link><pubDate>Thu, 27 Sep 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/09/vsts-name-change-in-azure-devops-effects-on-git-repositories/</guid><description>As I blogged in the past, it is super easy to build a VSTS Build (Now Azure DevOps Pipeline) to keep two repositories in sync. In that article one of the step is pushing the new code to the destination repositories with an url like: https://$(token)@myaddress.visualstudio.com/DefaultCollection, to automatically include a token to authenticate in the destination repository.
Now some of my build started to fail due to timeout and I immediately suspected the reason: the name change from VSTS to Azure DevOps changed the base url from accountname.</description></item><item><title>Copy Work Items between VSTS accounts TFS Instances</title><link>https://www.codewrecks.com/post/old/2018/09/copy-work-items-between-vsts-accounts-tfs-instances/</link><pubDate>Wed, 05 Sep 2018 08:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/09/copy-work-items-between-vsts-accounts-tfs-instances/</guid><description>This is a very common question: how can I copy Work Items information from a VSTS account to another account, or between VSTS and TFS. There are many scenarios where such functionality would be useful, but sadly enough, there is no option out-of-the box in the base product.
If you do not have images or other complex data inside your WI and you do not care to maintain history, you can simply create a query that load all the WI you want to copy, open it in excel with TFS / VSTS integration (be sure to select all columns of interest), then copy and past into another Excel instance connected to the destination project, press push and you are done.</description></item><item><title>Be sure to use latest version of Nuget Restore Task in VSTS Build</title><link>https://www.codewrecks.com/post/old/2018/08/be-sure-to-use-latest-version-of-nuget-restore-task-in-vsts-build/</link><pubDate>Mon, 27 Aug 2018 15:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/08/be-sure-to-use-latest-version-of-nuget-restore-task-in-vsts-build/</guid><description>If you have in VSTS some old build that uses Nuget restore task, it is time to check if you are using the new version, because if you still use the 0.x version you are missing some interesting features.
With VSTS build it is always a good habit to periodically check if some of the tasks have new version.
Here is as an example, how the version 0 is configured</description></item><item><title>Who moved my chees but now it is in a better place</title><link>https://www.codewrecks.com/post/old/2018/08/who-moved-my-chees-but-now-it-is-in-a-better-place/</link><pubDate>Mon, 13 Aug 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/08/who-moved-my-chees-but-now-it-is-in-a-better-place/</guid><description>I’m not a great fan when software I used everyday change position of stuffs, especially when main menu / navigation system changes. This is a problem generally known as “who moved my cheese” and lead to small frustration because you need to find where your everyday options were moved. Recently VSTS changed navigation system, from an horizontal menu to a vertical menu , rearranging the whole navigation, my cheese was moved, but this time for better.</description></item><item><title>Converting PowerShell Task in YAML</title><link>https://www.codewrecks.com/post/old/2018/08/converting-powershell-task-in-yaml/</link><pubDate>Tue, 07 Aug 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/08/converting-powershell-task-in-yaml/</guid><description>YAML Builds have many advantages over traditional build definitions, especially because YAML build definitions follows branching of code , a killer feature that is fantastic if you use GitFlow.
YAML Build definitions are stored in code, this allows them to follow branches, minimizing the need to maintain builds that should build code in different moment in time.
As an example I have a build where I have tasks to publish some Web Sites, if I had a new Web Site to publish, I can add another task in YAML build, but the build still work for older branches, especially for the master branch that represent my code in production.</description></item><item><title>Creating a Wiki with code in VSTS</title><link>https://www.codewrecks.com/post/old/2018/08/creating-a-wiki-with-code-in-vsts/</link><pubDate>Thu, 02 Aug 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/08/creating-a-wiki-with-code-in-vsts/</guid><description>Information spread is one of the key of success for Agile Teams, the ability to quick find information about a project, definition of UBIQUITOUS LANGUAGE and everything that can be related to the project should be prominent for each member of the project. In this scenario, **the information should also be near where it need to be, but at the same time it should be widely available to every member of the team **.</description></item><item><title>Leaving a VSTS Account</title><link>https://www.codewrecks.com/post/old/2018/06/leaving-a-vsts-account/</link><pubDate>Thu, 21 Jun 2018 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/06/leaving-a-vsts-account/</guid><description>As a VSTS trainer, it is quite common for me to made students create VSTS Accounts, play with them and being enlisted in those account to help them in various stuff. It happens also that some customer gives me temporary access to the VSTS account, and in all those years, many of them forgot to remove me from the account.
This is annoying because each time Visual Studio or other tools try to understand VSTS accounts I have right to access, the list is really long.</description></item><item><title>Public projects in VSTS</title><link>https://www.codewrecks.com/post/old/2018/05/public-projects-in-vsts/</link><pubDate>Mon, 07 May 2018 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/05/public-projects-in-vsts/</guid><description>This is a long and awaited feature, not because VSTS should fight GitHub as Open Source repository standard, but because an organization is often composed by many private projects and some projects that are public and Open Source.
You can read about the new feature in this blog post, the feature is in preview, but will become available to every account in the future. Enjoy it.
Gian Maria.</description></item><item><title>Run SonarCloud analysis in VSTS TFS Build</title><link>https://www.codewrecks.com/post/old/2018/03/run-sonarcloud-analysis-in-vsts-tfs-build/</link><pubDate>Sun, 25 Mar 2018 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/03/run-sonarcloud-analysis-in-vsts-tfs-build/</guid><description>Running a SonarQube analysis for TFS or VSTS is really easy because we can use a pre-made build tasks that requires few parameters and the game is done. If you have open source project it made lot of sense to use a public account in SonarCloud , so you do not need to maintain a sonar server on-premise and you can also share your public account with the community.
For open source projects, SonarCloud is available for you with zero effort and thanks to VSTS and TFS you can automate the analysis with few steps.</description></item><item><title>VSTS TFS use Wildcards for continuous integration in Git</title><link>https://www.codewrecks.com/post/old/2018/02/vsts-tfs-use-wildcards-for-continuous-integration-in-git/</link><pubDate>Tue, 20 Feb 2018 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/02/vsts-tfs-use-wildcards-for-continuous-integration-in-git/</guid><description>If you setup a build in VSTS / TFS against a git repository, you can choose to trigger the build when some specific branch changed. You can press plus button and a nice combobox appears to select the branch you want to monitor.
Figure 1: Adding a branch as trigger in VSTS / TFS Build
This means that if you add feature/1312_languageSelector, each time a new commit will be pushed on that branch, a new build will trigger.</description></item><item><title>New cool feature of VSTS to limit impact of erratic tests</title><link>https://www.codewrecks.com/post/old/2018/02/new-cool-feature-of-vsts-to-limit-impact-of-erratic-tests/</link><pubDate>Tue, 13 Feb 2018 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/02/new-cool-feature-of-vsts-to-limit-impact-of-erratic-tests/</guid><description>I’ve blogged some time ago about running UAT testing with a mix of Build + Release in VSTS. Actually, UAT testing are often hard to write, because they can be erratic. As an example, we have a software composed by 5 services that collaborates together, CQRS and Event Sourcing, so most of the tests are based on a typical pattern: Do something then wait for something to happen.
Writing tests that interact with the UI or are based on several services interacting togheter can be difficult.</description></item><item><title>VSTS Package packages failed to publish</title><link>https://www.codewrecks.com/post/old/2018/01/vsts-package-packages-failed-to-publish/</link><pubDate>Thu, 18 Jan 2018 18:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2018/01/vsts-package-packages-failed-to-publish/</guid><description>I have a build that publishes nuget packages on MyGet, we decided to move packages to VSTS internal package management, so I simply added another Build Task that pushes packages to VSTS internal feed. Sadly enough I got a really generic error
Error: An unexpected error occurred while trying to push the package with VstsNuGetPush.exe. Packages failed to publish Those two errors does not gives me real information on what went wrong, but looking in the whole log, I verified that the error happens when the task was trying to publish symbols packages (2).</description></item><item><title>Converting regular build in YAML build</title><link>https://www.codewrecks.com/post/old/2017/12/converting-regular-build-in-yaml-build/</link><pubDate>Thu, 14 Dec 2017 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/12/converting-regular-build-in-yaml-build/</guid><description>YAML build in VSTS / TFS is one of the most welcomed feature in the Continuous Integration engine , because it really opens many new possibilities. Two of the most important advantages you have with this approach are: build definitions will follow branches, so each branch can have a different definition, then, since the build is in the code, everything is audited, you can pull request build modification and you can test different build in branches as you do with code.</description></item><item><title>YAML build in VSTS</title><link>https://www.codewrecks.com/post/old/2017/11/yaml-build-in-vsts/</link><pubDate>Sun, 26 Nov 2017 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/11/yaml-build-in-vsts/</guid><description>One of the most exciting feature that was recently introduced in VSTS is the ability to create YAML Build. You need to enable this feature because it is still in preview and as usual you can enable for your account from the preview feature management
Figure 1: Enable YAML feature for the entire account
After you enable this feature, when you create a new build you can create a build based on YAML.</description></item><item><title>VSTS build failed test phase but 0 tests failed</title><link>https://www.codewrecks.com/post/old/2017/11/vsts-build-failed-test-but-0-test-failed/</link><pubDate>Sat, 18 Nov 2017 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/11/vsts-build-failed-test-but-0-test-failed/</guid><description>I had a strange situation where I have a build that suddenly starts signal failing tests, but actually zero test failed.
Figure 1: No test failed, but the test phase was marked as failed
As you can see in Figure 1, the Test step is marked failed, but actually I have not a single test failed, indeed a strange situation. To troubleshoot this problem, you need to select the failing step to verify the exact output of the task.</description></item><item><title>Configure a VSTS Linux agent with docker in minutes</title><link>https://www.codewrecks.com/post/old/2017/10/configure-a-vsts-linux-agent-with-docker-in-minutes/</link><pubDate>Sat, 14 Oct 2017 14:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/10/configure-a-vsts-linux-agent-with-docker-in-minutes/</guid><description>It is really simple to create a build agent for VSTS that runs in Linux and is capable of building and packaging your DotNetCore project, I’ve explained everything in a previous post, but I want to remind you that, with docker, the whole process is really simple.
Anyone knows that setting up a build machine often takes time. VSTS makes it super simple to install the Agent , just download a zip, call a script to configure the agent and the game is done.</description></item><item><title>Pause build and clear long build queue</title><link>https://www.codewrecks.com/post/old/2017/10/pause-build-and-clear-long-build-queue/</link><pubDate>Thu, 12 Oct 2017 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/10/pause-build-and-clear-long-build-queue/</guid><description>In VSTS / TFS Build system, you can change the status of the build, between three states: Enabled, Paused and Disabled. The Paused state is really special, because all the build trigger are still active and builds are queued, but all these queued build does not starts.
Figure 1: Paused build
Paused state should be used with great care, because if you forget a build in this state, you can end up with lots of queued build, as you can see in Figure 2: Figure 2: Really high number of build queued, because the build definition is paused.</description></item><item><title>Check Angular AoT with a TFS Build</title><link>https://www.codewrecks.com/post/old/2017/09/check-angular-aot-with-a-tfs-build/</link><pubDate>Sat, 23 Sep 2017 12:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/09/check-angular-aot-with-a-tfs-build/</guid><description>Developing with Angular is a real fun, but usually during development you serve the application without any optimization, mainly because you want to speedup the compilation and serving of your Angular application.
When it is time to release the software, usually you build with –prod switch and usually you also use the –aot switch (it seems to me that it is on by default on –prod in latest version of the ng compiler).</description></item><item><title>Choose agent at build queue time</title><link>https://www.codewrecks.com/post/old/2017/09/choose-agent-at-build-queue-time/</link><pubDate>Thu, 07 Sep 2017 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/09/choose-agent-at-build-queue-time/</guid><description>This is a simple feature that is not known very well and deserve a blog post. Sometimes you want to queue a build to a specific agent in a queue and this can be simply done using agent.name as a demand.
Demands are simple key/value pairs that allows the build engine to choose compatible agents and each agent automatically have a couple of capability to store computer name and agent name (they can be different)</description></item><item><title>VSTS agent on Ubuntu 1604 error in configuresh</title><link>https://www.codewrecks.com/post/old/2017/08/vsts-agent-on-ubuntu-16-04-error-in-configure-sh/</link><pubDate>Tue, 22 Aug 2017 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/vsts-agent-on-ubuntu-16-04-error-in-configure-sh/</guid><description>I’ve downloaded the build/release agent from VSTS page to install in my Ubuntu 16.04 system, but when I tried to run the configuration shell script I got the following error
Failed to initialize CoreCLR, HRESULT: 0x80131500 * This happens because I installed the version for Ubuntu 14.04 and not the one specifically compiled for Ubuntu 16.04. In my situation the error happened because the download page of my VSTS account does not list the version for Ubuntu 16.</description></item><item><title>New Nuget Task in VSTS Build</title><link>https://www.codewrecks.com/post/old/2017/08/new-nuget-task-in-vsts-build/</link><pubDate>Tue, 22 Aug 2017 06:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/new-nuget-task-in-vsts-build/</guid><description>If you edit a build in VSTS where you configured Nuget Packaging and Publishing, you can notice that all the old tasks to pack and publish are marked as deprecated.
Figure 1: Old nuget tasks that are now deprecated.
Deprecating a package is needed when the Author decide to completely replace the entire package, changing also the id. This is needed when the task will be completely redesigned and will work in a complete different way from the old version.</description></item><item><title>Mounting network share in Release Definition</title><link>https://www.codewrecks.com/post/old/2017/08/mounting-network-share-in-release-definition/</link><pubDate>Mon, 21 Aug 2017 19:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/mounting-network-share-in-release-definition/</guid><description>Using Deployment Groups with Release Management in VSTS is really nice, because you can use a pull release model, where the agent is running on machines that are deployment target, and all scripts are executed locally (instead of using PowerShell Remoting and WinRM).
A typical release definition depends on artifacts produced by a build and with VSTS sometimes it is convenient to store build artifacts in a network share instead that on VSTS.</description></item><item><title>Running UAT tests in a VSTS TFS release</title><link>https://www.codewrecks.com/post/old/2017/08/running-uat-tests-in-a-vsts-tfs-release/</link><pubDate>Thu, 17 Aug 2017 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/running-uat-tests-in-a-vsts-tfs-release/</guid><description>I’ve blogged on how to run UAT and integration tests during a VSTS Build; that solution works quite well but probably is not the right way to proceed. Generally speaking that build does its work but I have two main concerns.
Executing test with remote execution requires installation of test agent and involves WinRm , a beast that is not so easy to tame outside a domain
I’m deploying the new version of the application with an XCopy deployment, that is different from a real deploy to production.</description></item><item><title>Running UAT and integration tests during a VSTS Build</title><link>https://www.codewrecks.com/post/old/2017/08/running-uat-and-integration-tests-during-a-vsts-build/</link><pubDate>Sat, 05 Aug 2017 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/running-uat-and-integration-tests-during-a-vsts-build/</guid><description>There are a lots of small suggestions I’ve learned from experience when it is time to create a suite of integration / UAT test for your project. A UAT or integration test is a test that exercise the entire application, sometimes composed by several services that are collaborating to create the final result. The difference from UAT tests and Integration test, in my personal terminology, is that the UAT uses direct automation of User Interface, while an integration tests can skip the UI and exercise the system directly from public API (REST, MSMQ Commands, etc).</description></item><item><title>Dump all environment variables during a TFS VSTS Build</title><link>https://www.codewrecks.com/post/old/2017/08/dump-all-environment-variables-during-a-tfs-vsts-build/</link><pubDate>Fri, 04 Aug 2017 19:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/08/dump-all-environment-variables-during-a-tfs-vsts-build/</guid><description>Environment variables are really important during a build, especially because all Build variables are stored as environment variables, and this imply that most of the build context is stored inside them. One of the feature I miss most, is the ability to easily visualize on the result of the build a nice list of all the values of Environment variables. We need also to be aware of the fact that tasks can change environment variables during the build, so we need to be able to decide the exact point of the build where we want variables to be dumped.</description></item><item><title>Update GitVersion for large repositories</title><link>https://www.codewrecks.com/post/old/2017/04/update-gitversion-for-large-repositories/</link><pubDate>Sat, 22 Apr 2017 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2017/04/update-gitversion-for-large-repositories/</guid><description>As you know I’m a fanatic user of GitVersion in builds, and I’ve written a simple task to use it in a TFS Build automatically. This is the typical task that you write and forget, because it just works and you usually not have the need to upgrade it. But there is a build where I start to see really high execution timing for the task, as an example GitVersion needs 2 minutes to run.</description></item><item><title>Installing a linux Agent for VSTS build was never so easy</title><link>https://www.codewrecks.com/post/old/2016/03/installing-a-linux-agent-for-vsts-build-was-never-so-easy/</link><pubDate>Wed, 30 Mar 2016 16:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/03/installing-a-linux-agent-for-vsts-build-was-never-so-easy/</guid><description>If you installed Linux Agents for VSTS vNext build in the past, you already know that it was a simple experience, especially because the agent was installed with npm , so it is a matter of a couple of commands.
The agent is undergoing a substantial change, and in GitHub there is a project about VSTS Cross Platform Agent (CoreCLR), a new version of the agent, entirely written in CoreCLR that will substitute the closed source Windows agent and the actual XPlat agent.</description></item><item><title>Getting Work Item data in powershell through REST API</title><link>https://www.codewrecks.com/post/old/2016/01/getting-work-item-data-in-powershell-through-rest-api/</link><pubDate>Mon, 11 Jan 2016 17:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2016/01/getting-work-item-data-in-powershell-through-rest-api/</guid><description>VSTS and the latests versions of on-premise TFS has the ability to access data through REST API . This way to access TFS data is really convenient expecially if used from PowerShell scripts, because you do not need any external dependency, except being able to issue REST requests with the Invoke-RestRequest cmdlet.
To simplify accessing your VSTS account, you can enable alternate credentials, needed to issue request with simple Basic Authentication.</description></item><item><title>Integrating GitVersion and Gitflow in your vNext Build</title><link>https://www.codewrecks.com/post/old/2015/10/integrating-gitversion-and-gitflow-in-your-vnext-build/</link><pubDate>Sat, 17 Oct 2015 09:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/10/integrating-gitversion-and-gitflow-in-your-vnext-build/</guid><description>In previous article I’ve showed how to create a VSO build vNext to automatically publish a nuget package to Myget (or nuget) during a build. [Publishing a Nuget package to Nuget/Myget with VSO Build vNext]. Now it is time to create a more interesting build that automatically version your assemblies and nuget packages based on GitFlow.
GitFlow and GitVersion GitFlow is a simple convention to manage your branches in your Git repository to support a production branch, a developement branch and Feature/Support/Release/hotfix branches.</description></item><item><title>VSO vNext build error You cannot run the vsoAgentexe interactively</title><link>https://www.codewrecks.com/post/old/2015/05/vso-vnext-build-error-you-cannot-run-the-vsoagent-exe-interactively/</link><pubDate>Sat, 23 May 2015 07:00:37 +0200</pubDate><guid>https://www.codewrecks.com/post/old/2015/05/vso-vnext-build-error-you-cannot-run-the-vsoagent-exe-interactively/</guid><description>Error Symptom *: You installed and configured an Agent for the new Visual Studio Online Build System, and you decided not to run as a service, but interactively. When you double click the VsoAgent.exe executable you got this error. You cannot run the vsoAgent.exe interactively from within the Agent folder. Try running it from the parent folder
I’ve encountered this error on my main workstation machine, and I’m not sure why I got this error.</description></item></channel></rss>